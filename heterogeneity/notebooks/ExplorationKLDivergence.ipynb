{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:04:47.826112Z",
     "start_time": "2024-03-21T09:04:47.799900Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb06b0-77da-4d08-a7e2-5edef3262a8e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1944f791-a263-46a4-93b6-f21539e1ab6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:04:48.148764Z",
     "start_time": "2024-03-21T09:04:48.127076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adam/Projects/FL-heterogeneity/heterogeneity/notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "# you're in fl-heterogeneity/heterogeneity/notebooks\n",
    "sys.path.append(os.path.abspath(\"./../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "556367bd-44d7-4b01-9435-9998f034f016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:04:48.296274Z",
     "start_time": "2024-03-21T09:04:48.277822Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner, ShardPartitioner\n",
    "\n",
    "from heterogeneity.metrics import compute_kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b1258-ae96-447c-8c85-9549e4be3bcf",
   "metadata": {},
   "source": [
    "# KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9263b91-bcf9-40b0-a18b-6439eb3f9bcd",
   "metadata": {},
   "source": [
    "## IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a39c0b7-6757-4a73-96fb-b95520ddfae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:05:33.727972Z",
     "start_time": "2024-03-21T09:04:49.190290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample usage\n",
    "num_partitions = 10\n",
    "iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "\n",
    "\n",
    "num_partitions_to_cifar_iid_partitions = {}\n",
    "num_partitions_to_cifar_iid_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "for num_partitions in num_partitions_list:\n",
    "    iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "    cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "    num_partitions_to_cifar_iid_fds[num_partitions] = cifar_iid\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_iid_hellinger_distance = {}\n",
    "num_partitions_to_cifar_iid_hellinger_distance_list = {}\n",
    "for num_partitions, cifar_iid_fds in num_partitions_to_cifar_iid_fds.items():\n",
    "    metric_list, metric_avg = compute_kl_divergence(cifar_iid_fds.partitioners[\"train\"])\n",
    "    num_partitions_to_cifar_iid_hellinger_distance_list[num_partitions] = metric_list\n",
    "    num_partitions_to_cifar_iid_hellinger_distance[num_partitions] = metric_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dc556a8-9a57-4a0b-8912-174b11357664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:05:34.018650Z",
     "start_time": "2024-03-21T09:05:33.728876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c01bd_row0_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c01bd_row1_col0 {\n",
       "  background-color: #fcf4fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c01bd_row2_col0 {\n",
       "  background-color: #f5eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c01bd_row3_col0 {\n",
       "  background-color: #bfc9e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c01bd_row4_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c01bd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c01bd_level0_col0\" class=\"col_heading level0 col0\" >iid_kl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c01bd_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_c01bd_row0_col0\" class=\"data row0 col0\" >0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c01bd_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_c01bd_row1_col0\" class=\"data row1 col0\" >0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c01bd_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_c01bd_row2_col0\" class=\"data row2 col0\" >0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c01bd_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_c01bd_row3_col0\" class=\"data row3 col0\" >0.008409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c01bd_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_c01bd_row4_col0\" class=\"data row4 col0\" >0.027277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x4655c9720>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iid_kl_div_results = pd.Series(num_partitions_to_cifar_iid_hellinger_distance, name=\"iid_kl\").iloc[:-1].to_frame().style.background_gradient()\n",
    "iid_kl_div_results.index.name = \"num_partitions\"\n",
    "iid_kl_div_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8a642-ba9c-439d-8ba4-709e217c4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = num_partitions_to_cifar_iid_fds[100].partitioners[\"train\"].loa\n",
    "# distributions = []\n",
    "# for partition_id in num_partitions_to_cifar_iid_fds[100].partitioners[\"train\"].num_partitions:\n",
    "#     labels = num_partitions_to_cifar_iid_fds[100].partitioners[\"train\"].loa\n",
    "#     compute_distributions("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384551a-d1e2-48c3-8bdd-83c7b877f726",
   "metadata": {},
   "source": [
    "## Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dbe38ca-a22f-45e7-aca9-0de454757287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.1)\n",
      "(3, 0.3)\n",
      "(3, 1.0)\n",
      "(3, 3.0)\n",
      "(3, 10.0)\n",
      "(3, 100.0)\n",
      "(10, 0.1)\n",
      "(10, 0.3)\n",
      "(10, 1.0)\n",
      "(10, 3.0)\n",
      "(10, 10.0)\n",
      "(10, 100.0)\n",
      "(30, 0.1)\n",
      "(30, 0.3)\n",
      "(30, 1.0)\n",
      "(30, 3.0)\n",
      "(30, 10.0)\n",
      "(30, 100.0)\n",
      "(100, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0.3)\n",
      "(100, 1.0)\n",
      "(100, 3.0)\n",
      "(100, 10.0)\n",
      "(100, 100.0)\n",
      "(300, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (300, 0.1)\n",
      "(300, 0.3)\n",
      "(300, 1.0)\n",
      "(300, 3.0)\n",
      "(300, 10.0)\n",
      "(300, 100.0)\n",
      "(1000, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.1)\n",
      "(1000, 0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3, 0.3]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.3)\n",
      "(1000, 1.0)\n",
      "(1000, 3.0)\n",
      "(1000, 10.0)\n",
      "(1000, 100.0)\n"
     ]
    }
   ],
   "source": [
    "num_partitions = 10\n",
    "alpha = [0.1] * 10\n",
    "dirichlet_partitioner = DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\")\n",
    "cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dirichlet_partitioner})\n",
    "cifar_dir_partitions = [cifar_dir.load_partition(i) for i in range(num_partitions)]\n",
    "\n",
    "num_partitions_to_cifar_dir_partitions = {}\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "for num_partitions, alpha in itertools.product(num_partitions_list, alpha_list):\n",
    "    dir_partitioner =  DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\")\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha)] = cifar_dir\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_metric_list = {}\n",
    "num_partitions_to_cifar_dir_metric = {}\n",
    "for (num_partitions, alpha), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_kl_divergence(cifar_dir_fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_metric_list[(num_partitions, alpha)] = metric_list\n",
    "    num_partitions_to_cifar_dir_metric[(num_partitions, alpha)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1467a95a-c573-4f22-b64e-a08170a26cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9efe_row0_col0, #T_a9efe_row1_col0, #T_a9efe_row1_col1, #T_a9efe_row2_col0, #T_a9efe_row2_col1, #T_a9efe_row3_col0, #T_a9efe_row3_col1, #T_a9efe_row3_col2, #T_a9efe_row4_col0, #T_a9efe_row4_col1, #T_a9efe_row4_col2, #T_a9efe_row5_col0, #T_a9efe_row5_col1, #T_a9efe_row5_col2, #T_a9efe_row5_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9efe_row0_col1 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9efe_row0_col2 {\n",
       "  background-color: #c8cde4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row0_col3, #T_a9efe_row3_col4, #T_a9efe_row5_col4 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row0_col4 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row0_col5, #T_a9efe_row1_col5, #T_a9efe_row2_col5, #T_a9efe_row3_col5, #T_a9efe_row4_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row1_col2 {\n",
       "  background-color: #8fb4d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row1_col3 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row1_col4 {\n",
       "  background-color: #faf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row2_col2 {\n",
       "  background-color: #86b0d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row2_col3 {\n",
       "  background-color: #eae6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row2_col4 {\n",
       "  background-color: #faf2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row3_col3 {\n",
       "  background-color: #e5e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row4_col3 {\n",
       "  background-color: #e6e2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row4_col4 {\n",
       "  background-color: #f9f2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9efe_row5_col5 {\n",
       "  background-color: #fef6fb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9efe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >alpha</th>\n",
       "      <th id=\"T_a9efe_level0_col0\" class=\"col_heading level0 col0\" >0.100000</th>\n",
       "      <th id=\"T_a9efe_level0_col1\" class=\"col_heading level0 col1\" >0.300000</th>\n",
       "      <th id=\"T_a9efe_level0_col2\" class=\"col_heading level0 col2\" >1.000000</th>\n",
       "      <th id=\"T_a9efe_level0_col3\" class=\"col_heading level0 col3\" >3.000000</th>\n",
       "      <th id=\"T_a9efe_level0_col4\" class=\"col_heading level0 col4\" >10.000000</th>\n",
       "      <th id=\"T_a9efe_level0_col5\" class=\"col_heading level0 col5\" >100.000000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9efe_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_a9efe_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_a9efe_row0_col1\" class=\"data row0 col1\" >0.996390</td>\n",
       "      <td id=\"T_a9efe_row0_col2\" class=\"data row0 col2\" >0.275006</td>\n",
       "      <td id=\"T_a9efe_row0_col3\" class=\"data row0 col3\" >0.050017</td>\n",
       "      <td id=\"T_a9efe_row0_col4\" class=\"data row0 col4\" >0.021439</td>\n",
       "      <td id=\"T_a9efe_row0_col5\" class=\"data row0 col5\" >0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9efe_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_a9efe_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_a9efe_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_a9efe_row1_col2\" class=\"data row1 col2\" >0.429987</td>\n",
       "      <td id=\"T_a9efe_row1_col3\" class=\"data row1 col3\" >0.105258</td>\n",
       "      <td id=\"T_a9efe_row1_col4\" class=\"data row1 col4\" >0.035281</td>\n",
       "      <td id=\"T_a9efe_row1_col5\" class=\"data row1 col5\" >0.003430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9efe_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_a9efe_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_a9efe_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_a9efe_row2_col2\" class=\"data row2 col2\" >0.455574</td>\n",
       "      <td id=\"T_a9efe_row2_col3\" class=\"data row2 col3\" >0.135978</td>\n",
       "      <td id=\"T_a9efe_row2_col4\" class=\"data row2 col4\" >0.040678</td>\n",
       "      <td id=\"T_a9efe_row2_col5\" class=\"data row2 col5\" >0.004033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9efe_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_a9efe_row3_col0\" class=\"data row3 col0\" >nan</td>\n",
       "      <td id=\"T_a9efe_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_a9efe_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_a9efe_row3_col3\" class=\"data row3 col3\" >0.159319</td>\n",
       "      <td id=\"T_a9efe_row3_col4\" class=\"data row3 col4\" >0.046716</td>\n",
       "      <td id=\"T_a9efe_row3_col5\" class=\"data row3 col5\" >0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9efe_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_a9efe_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_a9efe_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_a9efe_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_a9efe_row4_col3\" class=\"data row4 col3\" >0.153635</td>\n",
       "      <td id=\"T_a9efe_row4_col4\" class=\"data row4 col4\" >0.044635</td>\n",
       "      <td id=\"T_a9efe_row4_col5\" class=\"data row4 col5\" >0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9efe_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_a9efe_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_a9efe_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_a9efe_row5_col2\" class=\"data row5 col2\" >nan</td>\n",
       "      <td id=\"T_a9efe_row5_col3\" class=\"data row5 col3\" >nan</td>\n",
       "      <td id=\"T_a9efe_row5_col4\" class=\"data row5 col4\" >0.049907</td>\n",
       "      <td id=\"T_a9efe_row5_col5\" class=\"data row5 col5\" >0.007669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x4655cac80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_dir = pd.Series(num_partitions_to_cifar_dir_metric).unstack(level=1)\n",
    "kl_dir.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "kl_dir.index.name = \"num_partitions\"\n",
    "kl_dir.columns.name = \"alpha\"\n",
    "kl_dir.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a24ad2b-cb62-4a65-8562-b6a76b86ad7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a1c63_row0_col0, #T_a1c63_row1_col0, #T_a1c63_row1_col1, #T_a1c63_row2_col0, #T_a1c63_row2_col1, #T_a1c63_row3_col0, #T_a1c63_row3_col1, #T_a1c63_row3_col2, #T_a1c63_row4_col0, #T_a1c63_row4_col1, #T_a1c63_row4_col2, #T_a1c63_row5_col0, #T_a1c63_row5_col1, #T_a1c63_row5_col2, #T_a1c63_row5_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1c63_row0_col1 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a1c63_row0_col2 {\n",
       "  background-color: #c8cde4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row0_col3, #T_a1c63_row3_col4, #T_a1c63_row5_col4 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row0_col4 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row0_col5, #T_a1c63_row1_col5, #T_a1c63_row2_col5, #T_a1c63_row3_col5, #T_a1c63_row4_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row1_col2 {\n",
       "  background-color: #8fb4d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row1_col3 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row1_col4 {\n",
       "  background-color: #faf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row2_col2 {\n",
       "  background-color: #86b0d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row2_col3 {\n",
       "  background-color: #eae6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row2_col4 {\n",
       "  background-color: #faf2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row3_col3 {\n",
       "  background-color: #e5e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row4_col3 {\n",
       "  background-color: #e6e2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row4_col4 {\n",
       "  background-color: #f9f2f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a1c63_row5_col5 {\n",
       "  background-color: #fef6fb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a1c63\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a1c63_level0_col0\" class=\"col_heading level0 col0\" colspan=\"6\">0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_a1c63_level1_col0\" class=\"col_heading level1 col0\" >0.100000</th>\n",
       "      <th id=\"T_a1c63_level1_col1\" class=\"col_heading level1 col1\" >0.300000</th>\n",
       "      <th id=\"T_a1c63_level1_col2\" class=\"col_heading level1 col2\" >1.000000</th>\n",
       "      <th id=\"T_a1c63_level1_col3\" class=\"col_heading level1 col3\" >3.000000</th>\n",
       "      <th id=\"T_a1c63_level1_col4\" class=\"col_heading level1 col4\" >10.000000</th>\n",
       "      <th id=\"T_a1c63_level1_col5\" class=\"col_heading level1 col5\" >100.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a1c63_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_a1c63_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_a1c63_row0_col1\" class=\"data row0 col1\" >0.996390</td>\n",
       "      <td id=\"T_a1c63_row0_col2\" class=\"data row0 col2\" >0.275006</td>\n",
       "      <td id=\"T_a1c63_row0_col3\" class=\"data row0 col3\" >0.050017</td>\n",
       "      <td id=\"T_a1c63_row0_col4\" class=\"data row0 col4\" >0.021439</td>\n",
       "      <td id=\"T_a1c63_row0_col5\" class=\"data row0 col5\" >0.002098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1c63_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_a1c63_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_a1c63_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_a1c63_row1_col2\" class=\"data row1 col2\" >0.429987</td>\n",
       "      <td id=\"T_a1c63_row1_col3\" class=\"data row1 col3\" >0.105258</td>\n",
       "      <td id=\"T_a1c63_row1_col4\" class=\"data row1 col4\" >0.035281</td>\n",
       "      <td id=\"T_a1c63_row1_col5\" class=\"data row1 col5\" >0.003430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1c63_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_a1c63_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_a1c63_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_a1c63_row2_col2\" class=\"data row2 col2\" >0.455574</td>\n",
       "      <td id=\"T_a1c63_row2_col3\" class=\"data row2 col3\" >0.135978</td>\n",
       "      <td id=\"T_a1c63_row2_col4\" class=\"data row2 col4\" >0.040678</td>\n",
       "      <td id=\"T_a1c63_row2_col5\" class=\"data row2 col5\" >0.004033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1c63_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_a1c63_row3_col0\" class=\"data row3 col0\" >nan</td>\n",
       "      <td id=\"T_a1c63_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_a1c63_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_a1c63_row3_col3\" class=\"data row3 col3\" >0.159319</td>\n",
       "      <td id=\"T_a1c63_row3_col4\" class=\"data row3 col4\" >0.046716</td>\n",
       "      <td id=\"T_a1c63_row3_col5\" class=\"data row3 col5\" >0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1c63_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_a1c63_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_a1c63_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_a1c63_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_a1c63_row4_col3\" class=\"data row4 col3\" >0.153635</td>\n",
       "      <td id=\"T_a1c63_row4_col4\" class=\"data row4 col4\" >0.044635</td>\n",
       "      <td id=\"T_a1c63_row4_col5\" class=\"data row4 col5\" >0.004530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a1c63_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_a1c63_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_a1c63_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_a1c63_row5_col2\" class=\"data row5 col2\" >nan</td>\n",
       "      <td id=\"T_a1c63_row5_col3\" class=\"data row5 col3\" >nan</td>\n",
       "      <td id=\"T_a1c63_row5_col4\" class=\"data row5 col4\" >0.049907</td>\n",
       "      <td id=\"T_a1c63_row5_col5\" class=\"data row5 col5\" >0.007669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x280a15ba0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.Series(num_partitions_to_cifar_dir_metric).to_frame().unstack(level=1)\n",
    "results.replace([np.inf, -np.inf], np.nan, inplace=False).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3ac81-c8e6-4aab-b7f4-dc31c04b5129",
   "metadata": {},
   "source": [
    "## Shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f14ac2c-372a-4494-9dd7-984c2a7d0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 3)\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "(10, 2)\n",
      "(10, 3)\n",
      "(10, 4)\n",
      "(10, 5)\n",
      "(30, 2)\n",
      "(30, 3)\n",
      "(30, 4)\n",
      "(30, 5)\n",
      "(100, 2)\n",
      "(100, 3)\n",
      "(100, 4)\n",
      "(100, 5)\n",
      "(300, 2)\n",
      "(300, 3)\n",
      "(300, 4)\n",
      "(300, 5)\n",
      "(1000, 2)\n",
      "(1000, 3)\n",
      "(1000, 4)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "params_to_partitioner = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "num_shards_per_partition_list = [2, 3, 4, 5]\n",
    "for num_partitions, num_shards_per_partition in itertools.product(num_partitions_list, num_shards_per_partition_list):\n",
    "    partitioner = ShardPartitioner(num_partitions=num_partitions, partition_by=\"label\", num_shards_per_partition=num_shards_per_partition)\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : partitioner})\n",
    "    params_to_partitioner[(num_partitions, num_shards_per_partition)] = fds\n",
    "\n",
    "parameters_to_shard_cifar_fds_metric_list = {}\n",
    "parameters_to_shard_cifar_fds_metric = {}\n",
    "for (num_partitions, num_shards_per_partition), fds in params_to_partitioner.items():\n",
    "    print((num_partitions, num_shards_per_partition))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_kl_divergence(fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, num_shards_per_partition)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    parameters_to_shard_cifar_fds_metric_list[(num_partitions, num_shards_per_partition)] = metric_list\n",
    "    parameters_to_shard_cifar_fds_metric[(num_partitions, num_shards_per_partition)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5c2da92-07da-4201-8a4d-169308c15312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/pandas/io/formats/style.py:3809: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  rng = smax - smin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4aef3_row0_col0, #T_4aef3_row0_col1, #T_4aef3_row0_col2, #T_4aef3_row0_col3, #T_4aef3_row1_col0, #T_4aef3_row1_col1, #T_4aef3_row1_col2, #T_4aef3_row1_col3, #T_4aef3_row2_col0, #T_4aef3_row2_col1, #T_4aef3_row2_col2, #T_4aef3_row2_col3, #T_4aef3_row3_col0, #T_4aef3_row3_col1, #T_4aef3_row3_col2, #T_4aef3_row3_col3, #T_4aef3_row4_col0, #T_4aef3_row4_col1, #T_4aef3_row4_col2, #T_4aef3_row4_col3, #T_4aef3_row5_col0, #T_4aef3_row5_col1, #T_4aef3_row5_col2, #T_4aef3_row5_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4aef3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_shards</th>\n",
       "      <th id=\"T_4aef3_level0_col0\" class=\"col_heading level0 col0\" >2</th>\n",
       "      <th id=\"T_4aef3_level0_col1\" class=\"col_heading level0 col1\" >3</th>\n",
       "      <th id=\"T_4aef3_level0_col2\" class=\"col_heading level0 col2\" >4</th>\n",
       "      <th id=\"T_4aef3_level0_col3\" class=\"col_heading level0 col3\" >5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4aef3_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_4aef3_row0_col0\" class=\"data row0 col0\" >inf</td>\n",
       "      <td id=\"T_4aef3_row0_col1\" class=\"data row0 col1\" >inf</td>\n",
       "      <td id=\"T_4aef3_row0_col2\" class=\"data row0 col2\" >inf</td>\n",
       "      <td id=\"T_4aef3_row0_col3\" class=\"data row0 col3\" >inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4aef3_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_4aef3_row1_col0\" class=\"data row1 col0\" >inf</td>\n",
       "      <td id=\"T_4aef3_row1_col1\" class=\"data row1 col1\" >inf</td>\n",
       "      <td id=\"T_4aef3_row1_col2\" class=\"data row1 col2\" >inf</td>\n",
       "      <td id=\"T_4aef3_row1_col3\" class=\"data row1 col3\" >inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4aef3_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_4aef3_row2_col0\" class=\"data row2 col0\" >inf</td>\n",
       "      <td id=\"T_4aef3_row2_col1\" class=\"data row2 col1\" >inf</td>\n",
       "      <td id=\"T_4aef3_row2_col2\" class=\"data row2 col2\" >inf</td>\n",
       "      <td id=\"T_4aef3_row2_col3\" class=\"data row2 col3\" >inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4aef3_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_4aef3_row3_col0\" class=\"data row3 col0\" >inf</td>\n",
       "      <td id=\"T_4aef3_row3_col1\" class=\"data row3 col1\" >inf</td>\n",
       "      <td id=\"T_4aef3_row3_col2\" class=\"data row3 col2\" >inf</td>\n",
       "      <td id=\"T_4aef3_row3_col3\" class=\"data row3 col3\" >inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4aef3_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_4aef3_row4_col0\" class=\"data row4 col0\" >inf</td>\n",
       "      <td id=\"T_4aef3_row4_col1\" class=\"data row4 col1\" >inf</td>\n",
       "      <td id=\"T_4aef3_row4_col2\" class=\"data row4 col2\" >inf</td>\n",
       "      <td id=\"T_4aef3_row4_col3\" class=\"data row4 col3\" >inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4aef3_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_4aef3_row5_col0\" class=\"data row5 col0\" >inf</td>\n",
       "      <td id=\"T_4aef3_row5_col1\" class=\"data row5 col1\" >inf</td>\n",
       "      <td id=\"T_4aef3_row5_col2\" class=\"data row5 col2\" >inf</td>\n",
       "      <td id=\"T_4aef3_row5_col3\" class=\"data row5 col3\" >inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x4655c8d60>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_emd_results = pd.Series(parameters_to_shard_cifar_fds_metric).unstack(level=1)\n",
    "shard_emd_results.index.name = \"num_partitions\"\n",
    "shard_emd_results.columns.name = \"num_shards\"\n",
    "shard_emd_results.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334a0cd-265c-4ab0-bff7-4ad7202515a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-heterogeneity",
   "language": "python",
   "name": "fl-heterogeneity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
