{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:36:02.010603Z",
     "start_time": "2024-03-26T10:36:01.898070Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb06b0-77da-4d08-a7e2-5edef3262a8e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1944f791-a263-46a4-93b6-f21539e1ab6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:36:02.209196Z",
     "start_time": "2024-03-26T10:36:02.199596Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "# you're in fl-heterogeneity/heterogeneity/notebooks\n",
    "sys.path.append(os.path.abspath(\"./../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556367bd-44d7-4b01-9435-9998f034f016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:36:03.704194Z",
     "start_time": "2024-03-26T10:36:02.560469Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner, ShardPartitioner, InnerDirichletPartitioner\n",
    "\n",
    "from heterogeneity.metrics import compute_kl_divergence\n",
    "from heterogeneity.utils import create_lognormal_partition_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b1258-ae96-447c-8c85-9549e4be3bcf",
   "metadata": {},
   "source": [
    "# KL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9263b91-bcf9-40b0-a18b-6439eb3f9bcd",
   "metadata": {},
   "source": [
    "## IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a39c0b7-6757-4a73-96fb-b95520ddfae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:05:33.727972Z",
     "start_time": "2024-03-21T09:04:49.190290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample usage\n",
    "num_partitions = 10\n",
    "iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "\n",
    "\n",
    "num_partitions_to_cifar_iid_partitions = {}\n",
    "num_partitions_to_cifar_iid_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "for num_partitions in num_partitions_list:\n",
    "    iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "    cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "    num_partitions_to_cifar_iid_fds[num_partitions] = cifar_iid\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_iid_hellinger_distance = {}\n",
    "num_partitions_to_cifar_iid_hellinger_distance_list = {}\n",
    "for num_partitions, cifar_iid_fds in num_partitions_to_cifar_iid_fds.items():\n",
    "    metric_list, metric_avg = compute_kl_divergence(cifar_iid_fds.partitioners[\"train\"])\n",
    "    num_partitions_to_cifar_iid_hellinger_distance_list[num_partitions] = metric_list\n",
    "    num_partitions_to_cifar_iid_hellinger_distance[num_partitions] = metric_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dc556a8-9a57-4a0b-8912-174b11357664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:05:34.018650Z",
     "start_time": "2024-03-21T09:05:33.728876Z"
    }
   },
   "outputs": [],
   "source": [
    "iid_kl_div_results = pd.Series(num_partitions_to_cifar_iid_hellinger_distance, name=\"iid_kl\").iloc[:-1].to_frame().style.background_gradient()\n",
    "iid_kl_div_results.index.name = \"num_partitions\"\n",
    "iid_kl_div_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8a642-ba9c-439d-8ba4-709e217c4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = num_partitions_to_cifar_iid_fds[100].partitioners[\"train\"].loa\n",
    "# distributions = []\n",
    "# for partition_id in num_partitions_to_cifar_iid_fds[100].partitioners[\"train\"].num_partitions:\n",
    "#     labels = num_partitions_to_cifar_iid_fds[100].partitioners[\"train\"].loa\n",
    "#     compute_distributions("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384551a-d1e2-48c3-8bdd-83c7b877f726",
   "metadata": {},
   "source": [
    "## Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dbe38ca-a22f-45e7-aca9-0de454757287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_partitions = 10\n",
    "alpha = [0.1] * 10\n",
    "dirichlet_partitioner = DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\")\n",
    "cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dirichlet_partitioner})\n",
    "cifar_dir_partitions = [cifar_dir.load_partition(i) for i in range(num_partitions)]\n",
    "\n",
    "num_partitions_to_cifar_dir_partitions = {}\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "for num_partitions, alpha in itertools.product(num_partitions_list, alpha_list):\n",
    "    dir_partitioner =  DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\")\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha)] = cifar_dir\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_metric_list = {}\n",
    "num_partitions_to_cifar_dir_metric = {}\n",
    "for (num_partitions, alpha), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_kl_divergence(cifar_dir_fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_metric_list[(num_partitions, alpha)] = metric_list\n",
    "    num_partitions_to_cifar_dir_metric[(num_partitions, alpha)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1467a95a-c573-4f22-b64e-a08170a26cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_dir = pd.Series(num_partitions_to_cifar_dir_metric).unstack(level=1)\n",
    "kl_dir.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "kl_dir.index.name = \"num_partitions\"\n",
    "kl_dir.columns.name = \"alpha\"\n",
    "kl_dir.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a24ad2b-cb62-4a65-8562-b6a76b86ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(num_partitions_to_cifar_dir_metric).to_frame().unstack(level=1)\n",
    "results.replace([np.inf, -np.inf], np.nan, inplace=False).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3ac81-c8e6-4aab-b7f4-dc31c04b5129",
   "metadata": {},
   "source": [
    "## Shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f14ac2c-372a-4494-9dd7-984c2a7d0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_partitioner = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "num_shards_per_partition_list = [2, 3, 4, 5]\n",
    "for num_partitions, num_shards_per_partition in itertools.product(num_partitions_list, num_shards_per_partition_list):\n",
    "    partitioner = ShardPartitioner(num_partitions=num_partitions, partition_by=\"label\", num_shards_per_partition=num_shards_per_partition)\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : partitioner})\n",
    "    params_to_partitioner[(num_partitions, num_shards_per_partition)] = fds\n",
    "\n",
    "parameters_to_shard_cifar_fds_metric_list = {}\n",
    "parameters_to_shard_cifar_fds_metric = {}\n",
    "for (num_partitions, num_shards_per_partition), fds in params_to_partitioner.items():\n",
    "    print((num_partitions, num_shards_per_partition))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_kl_divergence(fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, num_shards_per_partition)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    parameters_to_shard_cifar_fds_metric_list[(num_partitions, num_shards_per_partition)] = metric_list\n",
    "    parameters_to_shard_cifar_fds_metric[(num_partitions, num_shards_per_partition)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5c2da92-07da-4201-8a4d-169308c15312",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_emd_results = pd.Series(parameters_to_shard_cifar_fds_metric).unstack(level=1)\n",
    "shard_emd_results.index.name = \"num_partitions\"\n",
    "shard_emd_results.columns.name = \"num_shards\"\n",
    "shard_emd_results.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2928abdbafb0f60",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## InnerDirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e0ebf36c1d9aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-26T10:36:08.536283Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dataset_name = \"cifar10\"\n",
    "# num_partitions = 10\n",
    "# sigma = 0.3\n",
    "# partition_sizes = create_lognormal_partition_sizes(dataset_name, num_partitions, sigma)\n",
    "# \n",
    "# alpha = 0.1\n",
    "# dirichlet_partitioner = InnerDirichletPartitioner(partition_sizes=partition_sizes, partition_by=\"label\", alpha=0.1)\n",
    "# cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dirichlet_partitioner})\n",
    "# cifar_dir_partitions = [cifar_dir.load_partition(i) for i in range(num_partitions)]\n",
    "\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "sigma_list = [0.1, 0.3, 1., 3.]\n",
    "partition_sizes_dict = {}\n",
    "print(\"Data Generation\")\n",
    "for num_partitions, alpha, sigma in itertools.product(num_partitions_list, alpha_list, sigma_list):\n",
    "    print(num_partitions, alpha, sigma)\n",
    "    partition_sizes = create_lognormal_partition_sizes(dataset_name, num_partitions, sigma)\n",
    "    dir_partitioner =  InnerDirichletPartitioner(partition_sizes=partition_sizes, partition_by=\"label\", alpha=alpha)\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha, sigma)] = cifar_dir\n",
    "    partition_sizes_dict[(num_partitions, alpha, sigma)] = partition_sizes\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_metric_list = {}\n",
    "num_partitions_to_cifar_dir_metric = {}\n",
    "print(\"Metrics calculation\")\n",
    "for (num_partitions, alpha, sigma), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha, sigma))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_kl_divergence(cifar_dir_fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha, sigma)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_metric_list[(num_partitions, alpha, sigma)] = metric_list\n",
    "    num_partitions_to_cifar_dir_metric[(num_partitions, alpha, sigma)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1760d02fdba3265",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-heterogeneity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
