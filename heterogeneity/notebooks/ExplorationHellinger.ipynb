{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da047c64dbca004",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Aim: The aim of this notebook is to explore the Hellinger Distance dependency on the basic parameters of IidPartitioner and Dirichlet Partitioner when using CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e14b487a3d71a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520982c9c13a1727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:49:22.436108Z",
     "start_time": "2024-03-21T06:49:22.416947Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea296c4-2d51-4b70-8d79-3f95864eaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "# you're in fl-heterogeneity/heterogeneity/notebooks\n",
    "sys.path.append(os.path.abspath(\"./../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5897b2b6f67fab44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:49:26.203771Z",
     "start_time": "2024-03-21T06:49:22.437781Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner, ShardPartitioner\n",
    "\n",
    "from heterogeneity.metrics.hellinger_distance import compute_hellinger_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144dc39e4697f502",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ced94-e312-4a09-b9e8-5b632058e593",
   "metadata": {},
   "source": [
    "## IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f081d5d05df6f0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:49:57.037973Z",
     "start_time": "2024-03-21T06:49:51.886947Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1    5000\n",
       "2    5000\n",
       "3    5000\n",
       "4    5000\n",
       "5    5000\n",
       "6    5000\n",
       "7    5000\n",
       "8    5000\n",
       "9    5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample usage\n",
    "num_partitions = 10\n",
    "iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "# Basic statistics of the global train CIFAR10 data\n",
    "train = cifar_iid.load_split(\"train\")\n",
    "train_labels = train[\"label\"]\n",
    "pd.Series(train_labels).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6e30abc4d13d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f26e94d2836b46e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:52:43.548834Z",
     "start_time": "2024-03-21T06:52:37.063561Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c49f1_row0_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row1_col0 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row2_col0 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row3_col0 {\n",
       "  background-color: #ced0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row4_col0 {\n",
       "  background-color: #78abd0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c49f1_row5_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c49f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c49f1_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_c49f1_row0_col0\" class=\"data row0 col0\" >0.006003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_c49f1_row1_col0\" class=\"data row1 col0\" >0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_c49f1_row2_col0\" class=\"data row2 col0\" >0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_c49f1_row3_col0\" class=\"data row3 col0\" >0.044432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_c49f1_row4_col0\" class=\"data row4 col0\" >0.079355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_c49f1_row5_col0\" class=\"data row5 col0\" >0.156089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x174b480a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_partitions_to_cifar_iid_partitions = {}\n",
    "num_partitions_to_cifar_iid_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "for num_partitions in num_partitions_list:\n",
    "    iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "    cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "    num_partitions_to_cifar_iid_fds[num_partitions] = cifar_iid\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_iid_hellinger_distance = {}\n",
    "num_partitions_to_cifar_iid_hellinger_distance_list = {}\n",
    "for num_partitions, cifar_iid_fds in num_partitions_to_cifar_iid_fds.items():\n",
    "    hellinger_distance_list, avg_hellinger_distance = compute_hellinger_distance(cifar_iid_fds, \"train\")\n",
    "    num_partitions_to_cifar_iid_hellinger_distance_list[num_partitions] = hellinger_distance_list\n",
    "    num_partitions_to_cifar_iid_hellinger_distance[num_partitions] = avg_hellinger_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f0ba04b-19a7-4cba-8d28-a89161f89770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ec5f3_row0_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row1_col0 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row2_col0 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row3_col0 {\n",
       "  background-color: #ced0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row4_col0 {\n",
       "  background-color: #78abd0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ec5f3_row5_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ec5f3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ec5f3_level0_col0\" class=\"col_heading level0 col0\" >iid_helinger</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_ec5f3_row0_col0\" class=\"data row0 col0\" >0.006003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_ec5f3_row1_col0\" class=\"data row1 col0\" >0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_ec5f3_row2_col0\" class=\"data row2 col0\" >0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_ec5f3_row3_col0\" class=\"data row3 col0\" >0.044432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_ec5f3_row4_col0\" class=\"data row4 col0\" >0.079355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_ec5f3_row5_col0\" class=\"data row5 col0\" >0.156089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x374c53a60>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iid_helinger_results = pd.Series(num_partitions_to_cifar_iid_hellinger_distance, name=\"iid_helinger\").to_frame().style.background_gradient()\n",
    "iid_helinger_results.index.name = \"num_partitions\"\n",
    "iid_helinger_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17cac8-2f3a-43e7-9811-734a954bd739",
   "metadata": {},
   "source": [
    "Is it desired to that degree? When the num_partitions is 1000, then each partition is of size 5. That can make it indeed heterogeneus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9a284c484fbf8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "60176581-022a-4a0c-8b62-4944436fe33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_partitions = 10\n",
    "alpha = [0.1] * 10\n",
    "dirichlet_partitioner = DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\")\n",
    "cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dirichlet_partitioner})\n",
    "cifar_dir_partitions = [cifar_dir.load_partition(i) for i in range(num_partitions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b38b1b41-2fca-42b7-a3de-5f31bed37fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.1)\n",
      "(3, 0.3)\n",
      "(3, 1.0)\n",
      "(3, 3.0)\n",
      "(3, 10.0)\n",
      "(3, 100.0)\n",
      "(10, 0.1)\n",
      "(10, 0.3)\n",
      "(10, 1.0)\n",
      "(10, 3.0)\n",
      "(10, 10.0)\n",
      "(10, 100.0)\n",
      "(30, 0.1)\n",
      "(30, 0.3)\n",
      "(30, 1.0)\n",
      "(30, 3.0)\n",
      "(30, 10.0)\n",
      "(30, 100.0)\n",
      "(100, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0.3)\n",
      "(100, 1.0)\n",
      "(100, 3.0)\n",
      "(100, 10.0)\n",
      "(100, 100.0)\n",
      "(300, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (300, 0.1)\n",
      "(300, 0.3)\n",
      "(300, 1.0)\n",
      "(300, 3.0)\n",
      "(300, 10.0)\n",
      "(300, 100.0)\n",
      "(1000, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.1)\n",
      "(1000, 0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3, 0.3]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.3)\n",
      "(1000, 1.0)\n",
      "(1000, 3.0)\n",
      "(1000, 10.0)\n",
      "(1000, 100.0)\n"
     ]
    }
   ],
   "source": [
    "num_partitions_to_cifar_dir_partitions = {}\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "for num_partitions, alpha in itertools.product(num_partitions_list, alpha_list):\n",
    "    dir_partitioner =  DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\", self_balancing=False)\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha)] = cifar_dir\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_hellinger_distance_list = {}\n",
    "num_partitions_to_cifar_dir_hellinger_distance = {}\n",
    "for (num_partitions, alpha), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha))\n",
    "    try:\n",
    "        hellinger_distance_list, avg_hellinger_distance = hellinger_distance(cifar_dir_fds, \"train\")\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha)}\")\n",
    "        hellinger_distance_list, avg_hellinger_distance = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_hellinger_distance_list[(num_partitions, alpha)] = hellinger_distance_list\n",
    "    num_partitions_to_cifar_dir_hellinger_distance[(num_partitions, alpha)] = avg_hellinger_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4535e38e-99c1-4c89-8efe-e09eac516a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2a01_row0_col0 {\n",
       "  background-color: #1e80b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row0_col1 {\n",
       "  background-color: #60a1ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row0_col2 {\n",
       "  background-color: #b9c6e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row0_col3 {\n",
       "  background-color: #eae6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row0_col4 {\n",
       "  background-color: #f4edf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row0_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col0 {\n",
       "  background-color: #034e7b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row1_col1 {\n",
       "  background-color: #167bb6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row1_col2 {\n",
       "  background-color: #96b6d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col3 {\n",
       "  background-color: #dad9ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col4 {\n",
       "  background-color: #efe9f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col5 {\n",
       "  background-color: #fef6fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col0 {\n",
       "  background-color: #023e62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row2_col1 {\n",
       "  background-color: #197db7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row2_col2 {\n",
       "  background-color: #91b5d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col3 {\n",
       "  background-color: #d3d4e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col4 {\n",
       "  background-color: #eee8f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col5, #T_a2a01_row3_col5, #T_a2a01_row4_col5 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row3_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row3_col1 {\n",
       "  background-color: #0771b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row3_col2 {\n",
       "  background-color: #81aed2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row3_col3 {\n",
       "  background-color: #d0d1e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row3_col4 {\n",
       "  background-color: #ece7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row4_col0, #T_a2a01_row5_col0, #T_a2a01_row5_col1 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row4_col1 {\n",
       "  background-color: #056ead;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row4_col2 {\n",
       "  background-color: #86b0d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row4_col3 {\n",
       "  background-color: #d1d2e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row4_col4 {\n",
       "  background-color: #ede7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row5_col2 {\n",
       "  background-color: #7bacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row5_col3 {\n",
       "  background-color: #cccfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row5_col4 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row5_col5 {\n",
       "  background-color: #fbf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2a01\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >alpha</th>\n",
       "      <th id=\"T_a2a01_level0_col0\" class=\"col_heading level0 col0\" >0.100000</th>\n",
       "      <th id=\"T_a2a01_level0_col1\" class=\"col_heading level0 col1\" >0.300000</th>\n",
       "      <th id=\"T_a2a01_level0_col2\" class=\"col_heading level0 col2\" >1.000000</th>\n",
       "      <th id=\"T_a2a01_level0_col3\" class=\"col_heading level0 col3\" >3.000000</th>\n",
       "      <th id=\"T_a2a01_level0_col4\" class=\"col_heading level0 col4\" >10.000000</th>\n",
       "      <th id=\"T_a2a01_level0_col5\" class=\"col_heading level0 col5\" >100.000000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_a2a01_row0_col0\" class=\"data row0 col0\" >0.465201</td>\n",
       "      <td id=\"T_a2a01_row0_col1\" class=\"data row0 col1\" >0.370950</td>\n",
       "      <td id=\"T_a2a01_row0_col2\" class=\"data row0 col2\" >0.227716</td>\n",
       "      <td id=\"T_a2a01_row0_col3\" class=\"data row0 col3\" >0.109010</td>\n",
       "      <td id=\"T_a2a01_row0_col4\" class=\"data row0 col4\" >0.071695</td>\n",
       "      <td id=\"T_a2a01_row0_col5\" class=\"data row0 col5\" >0.022788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_a2a01_row1_col0\" class=\"data row1 col0\" >0.613713</td>\n",
       "      <td id=\"T_a2a01_row1_col1\" class=\"data row1 col1\" >0.476372</td>\n",
       "      <td id=\"T_a2a01_row1_col2\" class=\"data row1 col2\" >0.290158</td>\n",
       "      <td id=\"T_a2a01_row1_col3\" class=\"data row1 col3\" >0.155027</td>\n",
       "      <td id=\"T_a2a01_row1_col4\" class=\"data row1 col4\" >0.091440</td>\n",
       "      <td id=\"T_a2a01_row1_col5\" class=\"data row1 col5\" >0.028729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_a2a01_row2_col0\" class=\"data row2 col0\" >0.651914</td>\n",
       "      <td id=\"T_a2a01_row2_col1\" class=\"data row2 col1\" >0.471448</td>\n",
       "      <td id=\"T_a2a01_row2_col2\" class=\"data row2 col2\" >0.297516</td>\n",
       "      <td id=\"T_a2a01_row2_col3\" class=\"data row2 col3\" >0.174453</td>\n",
       "      <td id=\"T_a2a01_row2_col4\" class=\"data row2 col4\" >0.097322</td>\n",
       "      <td id=\"T_a2a01_row2_col5\" class=\"data row2 col5\" >0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_a2a01_row3_col0\" class=\"data row3 col0\" >0.667463</td>\n",
       "      <td id=\"T_a2a01_row3_col1\" class=\"data row3 col1\" >0.503658</td>\n",
       "      <td id=\"T_a2a01_row3_col2\" class=\"data row3 col2\" >0.324196</td>\n",
       "      <td id=\"T_a2a01_row3_col3\" class=\"data row3 col3\" >0.186368</td>\n",
       "      <td id=\"T_a2a01_row3_col4\" class=\"data row3 col4\" >0.103555</td>\n",
       "      <td id=\"T_a2a01_row3_col5\" class=\"data row3 col5\" >0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_a2a01_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_a2a01_row4_col1\" class=\"data row4 col1\" >0.511364</td>\n",
       "      <td id=\"T_a2a01_row4_col2\" class=\"data row4 col2\" >0.315759</td>\n",
       "      <td id=\"T_a2a01_row4_col3\" class=\"data row4 col3\" >0.182981</td>\n",
       "      <td id=\"T_a2a01_row4_col4\" class=\"data row4 col4\" >0.101346</td>\n",
       "      <td id=\"T_a2a01_row4_col5\" class=\"data row4 col5\" >0.032604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_a2a01_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_a2a01_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_a2a01_row5_col2\" class=\"data row5 col2\" >0.334892</td>\n",
       "      <td id=\"T_a2a01_row5_col3\" class=\"data row5 col3\" >0.191701</td>\n",
       "      <td id=\"T_a2a01_row5_col4\" class=\"data row5 col4\" >0.106884</td>\n",
       "      <td id=\"T_a2a01_row5_col5\" class=\"data row5 col5\" >0.042349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3752ac6a0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hel_dir = pd.Series(num_partitions_to_cifar_dir_hellinger_distance).unstack(level=1)#.style.background_gradient(axis=None)\n",
    "hel_dir.index.name = \"num_partitions\"\n",
    "hel_dir.columns.name = \"alpha\"\n",
    "hel_dir.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63b4df5d-9535-40dc-9a35-65ed944489bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.1)\n",
      "(3, 0.3)\n",
      "(3, 1.0)\n",
      "(3, 3.0)\n",
      "(3, 10.0)\n",
      "(3, 100.0)\n",
      "(10, 0.1)\n",
      "(10, 0.3)\n",
      "(10, 1.0)\n",
      "(10, 3.0)\n",
      "(10, 10.0)\n",
      "(10, 100.0)\n",
      "(30, 0.1)\n",
      "(30, 0.3)\n",
      "(30, 1.0)\n",
      "(30, 3.0)\n",
      "(30, 10.0)\n",
      "(30, 100.0)\n",
      "(100, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0.3)\n",
      "(100, 1.0)\n",
      "(100, 3.0)\n",
      "(100, 10.0)\n",
      "(100, 100.0)\n",
      "(300, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (300, 0.1)\n",
      "(300, 0.3)\n",
      "(300, 1.0)\n",
      "(300, 3.0)\n",
      "(300, 10.0)\n",
      "(300, 100.0)\n",
      "(1000, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.1)\n",
      "(1000, 0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3, 0.3]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.3)\n",
      "(1000, 1.0)\n",
      "(1000, 3.0)\n",
      "(1000, 10.0)\n",
      "(1000, 100.0)\n"
     ]
    }
   ],
   "source": [
    "num_partitions_to_cifar_dir_partitions = {}\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "for num_partitions, alpha in itertools.product(num_partitions_list, alpha_list):\n",
    "    dir_partitioner =  DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\", self_balancing=True)\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha)] = cifar_dir\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_hellinger_distance_list = {}\n",
    "num_partitions_to_cifar_dir_hellinger_distance = {}\n",
    "for (num_partitions, alpha), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha))\n",
    "    try:\n",
    "        hellinger_distance_list, avg_hellinger_distance = hellinger_distance(cifar_dir_fds, \"train\")\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha)}\")\n",
    "        hellinger_distance_list, avg_hellinger_distance = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_hellinger_distance_list[(num_partitions, alpha)] = hellinger_distance_list\n",
    "    num_partitions_to_cifar_dir_hellinger_distance[(num_partitions, alpha)] = avg_hellinger_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4e3afe2-e52b-4983-bd76-be6dea58f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_af86b_row0_col0 {\n",
       "  background-color: #056ba7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row0_col1 {\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row0_col2 {\n",
       "  background-color: #a5bddb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row0_col3 {\n",
       "  background-color: #dcdaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row0_col4 {\n",
       "  background-color: #f5eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row0_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row1_col0 {\n",
       "  background-color: #034369;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row1_col1 {\n",
       "  background-color: #0d75b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row1_col2 {\n",
       "  background-color: #75a9cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row1_col3 {\n",
       "  background-color: #c4cbe3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row1_col4 {\n",
       "  background-color: #e4e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row1_col5, #T_af86b_row2_col5 {\n",
       "  background-color: #fef6fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row2_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row2_col1 {\n",
       "  background-color: #056dab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row2_col2 {\n",
       "  background-color: #69a5cc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row2_col3, #T_af86b_row5_col3 {\n",
       "  background-color: #bdc8e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row2_col4 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row3_col0 {\n",
       "  background-color: #023a5b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row3_col1 {\n",
       "  background-color: #056aa6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row3_col2 {\n",
       "  background-color: #6ba5cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row3_col3, #T_af86b_row4_col3 {\n",
       "  background-color: #bcc7e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row3_col4 {\n",
       "  background-color: #e7e3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row3_col5, #T_af86b_row4_col5 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row4_col0, #T_af86b_row5_col0, #T_af86b_row5_col1 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row4_col1 {\n",
       "  background-color: #0567a1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row4_col2 {\n",
       "  background-color: #6da6cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row4_col4 {\n",
       "  background-color: #e5e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row5_col2 {\n",
       "  background-color: #63a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row5_col4 {\n",
       "  background-color: #e6e2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row5_col5 {\n",
       "  background-color: #fbf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_af86b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_af86b_level0_col0\" class=\"col_heading level0 col0\" colspan=\"6\">0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_af86b_level1_col0\" class=\"col_heading level1 col0\" >0.100000</th>\n",
       "      <th id=\"T_af86b_level1_col1\" class=\"col_heading level1 col1\" >0.300000</th>\n",
       "      <th id=\"T_af86b_level1_col2\" class=\"col_heading level1 col2\" >1.000000</th>\n",
       "      <th id=\"T_af86b_level1_col3\" class=\"col_heading level1 col3\" >3.000000</th>\n",
       "      <th id=\"T_af86b_level1_col4\" class=\"col_heading level1 col4\" >10.000000</th>\n",
       "      <th id=\"T_af86b_level1_col5\" class=\"col_heading level1 col5\" >100.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_af86b_row0_col0\" class=\"data row0 col0\" >0.567639</td>\n",
       "      <td id=\"T_af86b_row0_col1\" class=\"data row0 col1\" >0.440146</td>\n",
       "      <td id=\"T_af86b_row0_col2\" class=\"data row0 col2\" >0.287541</td>\n",
       "      <td id=\"T_af86b_row0_col3\" class=\"data row0 col3\" >0.161999</td>\n",
       "      <td id=\"T_af86b_row0_col4\" class=\"data row0 col4\" >0.071695</td>\n",
       "      <td id=\"T_af86b_row0_col5\" class=\"data row0 col5\" >0.022788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_af86b_row1_col0\" class=\"data row1 col0\" >0.691987</td>\n",
       "      <td id=\"T_af86b_row1_col1\" class=\"data row1 col1\" >0.530651</td>\n",
       "      <td id=\"T_af86b_row1_col2\" class=\"data row1 col2\" >0.371551</td>\n",
       "      <td id=\"T_af86b_row1_col3\" class=\"data row1 col3\" >0.223615</td>\n",
       "      <td id=\"T_af86b_row1_col4\" class=\"data row1 col4\" >0.134834</td>\n",
       "      <td id=\"T_af86b_row1_col5\" class=\"data row1 col5\" >0.028729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_af86b_row2_col0\" class=\"data row2 col0\" >0.721607</td>\n",
       "      <td id=\"T_af86b_row2_col1\" class=\"data row2 col1\" >0.558678</td>\n",
       "      <td id=\"T_af86b_row2_col2\" class=\"data row2 col2\" >0.387039</td>\n",
       "      <td id=\"T_af86b_row2_col3\" class=\"data row2 col3\" >0.238245</td>\n",
       "      <td id=\"T_af86b_row2_col4\" class=\"data row2 col4\" >0.115445</td>\n",
       "      <td id=\"T_af86b_row2_col5\" class=\"data row2 col5\" >0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_af86b_row3_col0\" class=\"data row3 col0\" >0.715659</td>\n",
       "      <td id=\"T_af86b_row3_col1\" class=\"data row3 col1\" >0.569919</td>\n",
       "      <td id=\"T_af86b_row3_col2\" class=\"data row3 col2\" >0.384234</td>\n",
       "      <td id=\"T_af86b_row3_col3\" class=\"data row3 col3\" >0.240813</td>\n",
       "      <td id=\"T_af86b_row3_col4\" class=\"data row3 col4\" >0.125372</td>\n",
       "      <td id=\"T_af86b_row3_col5\" class=\"data row3 col5\" >0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_af86b_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_af86b_row4_col1\" class=\"data row4 col1\" >0.583560</td>\n",
       "      <td id=\"T_af86b_row4_col2\" class=\"data row4 col2\" >0.381126</td>\n",
       "      <td id=\"T_af86b_row4_col3\" class=\"data row4 col3\" >0.238532</td>\n",
       "      <td id=\"T_af86b_row4_col4\" class=\"data row4 col4\" >0.132240</td>\n",
       "      <td id=\"T_af86b_row4_col5\" class=\"data row4 col5\" >0.032604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_af86b_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_af86b_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_af86b_row5_col2\" class=\"data row5 col2\" >0.396759</td>\n",
       "      <td id=\"T_af86b_row5_col3\" class=\"data row5 col3\" >0.236577</td>\n",
       "      <td id=\"T_af86b_row5_col4\" class=\"data row5 col4\" >0.129837</td>\n",
       "      <td id=\"T_af86b_row5_col5\" class=\"data row5 col5\" >0.042934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11ad6c130>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(num_partitions_to_cifar_dir_hellinger_distance).to_frame().unstack(level=1).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e0e67-2aaa-4d03-9f9b-3c158fd1283f",
   "metadata": {},
   "source": [
    "The self_balancing (size balancing) creates more heterogenous dataset division."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a7086-602f-4606-9675-660a9e64cfe9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3428971c-5551-4539-a363-25827a182dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 3)\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "(10, 2)\n",
      "(10, 3)\n",
      "(10, 4)\n",
      "(10, 5)\n",
      "(30, 2)\n",
      "(30, 3)\n",
      "(30, 4)\n",
      "(30, 5)\n",
      "(100, 2)\n",
      "(100, 3)\n",
      "(100, 4)\n",
      "(100, 5)\n",
      "(300, 2)\n",
      "(300, 3)\n",
      "(300, 4)\n",
      "(300, 5)\n",
      "(1000, 2)\n",
      "(1000, 3)\n",
      "(1000, 4)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "params_to_partitioner = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "num_shards_per_partition_list = [2, 3, 4, 5]\n",
    "for num_partitions, num_shards_per_partition in itertools.product(num_partitions_list, num_shards_per_partition_list):\n",
    "    partitioner = ShardPartitioner(num_partitions=num_partitions, partition_by=\"label\", num_shards_per_partition=num_shards_per_partition)\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : partitioner})\n",
    "    params_to_partitioner[(num_partitions, num_shards_per_partition)] = fds\n",
    "\n",
    "parameters_to_shard_cifar_fds_metric_list = {}\n",
    "parameters_to_shard_cifar_fds_metric = {}\n",
    "for (num_partitions, num_shards_per_partition), fds in params_to_partitioner.items():\n",
    "    print((num_partitions, num_shards_per_partition))\n",
    "    try:\n",
    "        metric_list, avg_metric = hellinger_distance(fds, \"train\")\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, num_shards_per_partition)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    parameters_to_shard_cifar_fds_metric_list[(num_partitions, num_shards_per_partition)] = metric_list\n",
    "    parameters_to_shard_cifar_fds_metric[(num_partitions, num_shards_per_partition)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e698d33c-0b02-4db5-9597-de6b616fef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4443_row0_col0 {\n",
       "  background-color: #81aed2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row0_col1, #T_e4443_row0_col3 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row0_col2 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row1_col0 {\n",
       "  background-color: #034165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row1_col1 {\n",
       "  background-color: #0d75b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row1_col2 {\n",
       "  background-color: #4094c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row1_col3 {\n",
       "  background-color: #9cb9d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row2_col0, #T_e4443_row4_col0, #T_e4443_row5_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row2_col1 {\n",
       "  background-color: #056dab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row2_col2 {\n",
       "  background-color: #63a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row2_col3 {\n",
       "  background-color: #a9bfdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row3_col0 {\n",
       "  background-color: #023b5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row3_col1 {\n",
       "  background-color: #0771b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row3_col2 {\n",
       "  background-color: #4697c4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row3_col3 {\n",
       "  background-color: #8eb3d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row4_col1 {\n",
       "  background-color: #056fae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row4_col2 {\n",
       "  background-color: #4c99c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row4_col3 {\n",
       "  background-color: #8fb4d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row5_col1 {\n",
       "  background-color: #056caa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row5_col2 {\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row5_col3 {\n",
       "  background-color: #96b6d7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4443\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_shards</th>\n",
       "      <th id=\"T_e4443_level0_col0\" class=\"col_heading level0 col0\" >2</th>\n",
       "      <th id=\"T_e4443_level0_col1\" class=\"col_heading level0 col1\" >3</th>\n",
       "      <th id=\"T_e4443_level0_col2\" class=\"col_heading level0 col2\" >4</th>\n",
       "      <th id=\"T_e4443_level0_col3\" class=\"col_heading level0 col3\" >5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_e4443_row0_col0\" class=\"data row0 col0\" >0.614130</td>\n",
       "      <td id=\"T_e4443_row0_col1\" class=\"data row0 col1\" >0.506585</td>\n",
       "      <td id=\"T_e4443_row0_col2\" class=\"data row0 col2\" >0.493643</td>\n",
       "      <td id=\"T_e4443_row0_col3\" class=\"data row0 col3\" >0.506547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_e4443_row1_col0\" class=\"data row1 col0\" >0.743496</td>\n",
       "      <td id=\"T_e4443_row1_col1\" class=\"data row1 col1\" >0.681302</td>\n",
       "      <td id=\"T_e4443_row1_col2\" class=\"data row1 col2\" >0.649515</td>\n",
       "      <td id=\"T_e4443_row1_col3\" class=\"data row1 col3\" >0.597347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_e4443_row2_col0\" class=\"data row2 col0\" >0.750597</td>\n",
       "      <td id=\"T_e4443_row2_col1\" class=\"data row2 col1\" >0.692119</td>\n",
       "      <td id=\"T_e4443_row2_col2\" class=\"data row2 col2\" >0.630778</td>\n",
       "      <td id=\"T_e4443_row2_col3\" class=\"data row2 col3\" >0.588314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_e4443_row3_col0\" class=\"data row3 col0\" >0.748501</td>\n",
       "      <td id=\"T_e4443_row3_col1\" class=\"data row3 col1\" >0.685527</td>\n",
       "      <td id=\"T_e4443_row3_col2\" class=\"data row3 col2\" >0.645899</td>\n",
       "      <td id=\"T_e4443_row3_col3\" class=\"data row3 col3\" >0.605997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_e4443_row4_col0\" class=\"data row4 col0\" >0.751315</td>\n",
       "      <td id=\"T_e4443_row4_col1\" class=\"data row4 col1\" >0.689076</td>\n",
       "      <td id=\"T_e4443_row4_col2\" class=\"data row4 col2\" >0.643505</td>\n",
       "      <td id=\"T_e4443_row4_col3\" class=\"data row4 col3\" >0.605235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_e4443_row5_col0\" class=\"data row5 col0\" >0.751587</td>\n",
       "      <td id=\"T_e4443_row5_col1\" class=\"data row5 col1\" >0.692730</td>\n",
       "      <td id=\"T_e4443_row5_col2\" class=\"data row5 col2\" >0.647640</td>\n",
       "      <td id=\"T_e4443_row5_col3\" class=\"data row5 col3\" >0.600940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x36415bf70>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_emd_results = pd.Series(parameters_to_shard_cifar_fds_metric).unstack(level=1)\n",
    "shard_emd_results.index.name = \"num_partitions\"\n",
    "shard_emd_results.columns.name = \"num_shards\"\n",
    "shard_emd_results.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fef0826-0b5f-4812-9169-6593dfa509ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(0, 2),\n",
       "            (0, 3),\n",
       "            (0, 4),\n",
       "            (0, 5)],\n",
       "           )"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_emd_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0039cc88-7c12-49e4-b89e-d3831a5e67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_emd_results.columns = [\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "476d1793-1474-401a-aeff-f07e3240b618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>2</th>\n",
       "      <td>0.614130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.506547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>2</th>\n",
       "      <td>0.743496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.681302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.597347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">30</th>\n",
       "      <th>2</th>\n",
       "      <td>0.750597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.692119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.588314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>2</th>\n",
       "      <td>0.748501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.605997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">300</th>\n",
       "      <th>2</th>\n",
       "      <td>0.751315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.605235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1000</th>\n",
       "      <th>2</th>\n",
       "      <td>0.751587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.692730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                \n",
       "3    2  0.614130\n",
       "     3  0.506585\n",
       "     4  0.493643\n",
       "     5  0.506547\n",
       "10   2  0.743496\n",
       "     3  0.681302\n",
       "     4  0.649515\n",
       "     5  0.597347\n",
       "30   2  0.750597\n",
       "     3  0.692119\n",
       "     4  0.630778\n",
       "     5  0.588314\n",
       "100  2  0.748501\n",
       "     3  0.685527\n",
       "     4  0.645899\n",
       "     5  0.605997\n",
       "300  2  0.751315\n",
       "     3  0.689076\n",
       "     4  0.643505\n",
       "     5  0.605235\n",
       "1000 2  0.751587\n",
       "     3  0.692730\n",
       "     4  0.647640\n",
       "     5  0.600940"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_emd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a035543-f81a-4012-badb-c426d9a41f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-heterogeneity",
   "language": "python",
   "name": "fl-heterogeneity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
