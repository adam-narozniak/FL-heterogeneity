{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da047c64dbca004",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Aim: The aim of this notebook is to explore the Hellinger Distance dependency on the basic parameters of IidPartitioner and Dirichlet Partitioner when using CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e14b487a3d71a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520982c9c13a1727",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:11:02.065657Z",
     "start_time": "2024-03-26T10:11:02.043704Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea296c4-2d51-4b70-8d79-3f95864eaf78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T10:11:02.238723Z",
     "start_time": "2024-03-26T10:11:02.223454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adam/Projects/FL-heterogeneity/heterogeneity/notebooks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "# you're in fl-heterogeneity/heterogeneity/notebooks\n",
    "sys.path.append(os.path.abspath(\"./../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5897b2b6f67fab44",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:11:02.387207Z",
     "start_time": "2024-03-26T10:11:02.371204Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner, DirichletPartitioner, ShardPartitioner, InnerDirichletPartitioner\n",
    "\n",
    "from heterogeneity.metrics.hellinger_distance import compute_hellinger_distance\n",
    "from heterogeneity.utils import create_lognormal_partition_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144dc39e4697f502",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ced94-e312-4a09-b9e8-5b632058e593",
   "metadata": {},
   "source": [
    "## IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f081d5d05df6f0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:49:57.037973Z",
     "start_time": "2024-03-21T06:49:51.886947Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1    5000\n",
       "2    5000\n",
       "3    5000\n",
       "4    5000\n",
       "5    5000\n",
       "6    5000\n",
       "7    5000\n",
       "8    5000\n",
       "9    5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample usage\n",
    "num_partitions = 10\n",
    "iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "# Basic statistics of the global train CIFAR10 data\n",
    "train = cifar_iid.load_split(\"train\")\n",
    "train_labels = train[\"label\"]\n",
    "pd.Series(train_labels).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6e30abc4d13d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f26e94d2836b46e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T06:52:43.548834Z",
     "start_time": "2024-03-21T06:52:37.063561Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c49f1_row0_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row1_col0 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row2_col0 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row3_col0 {\n",
       "  background-color: #ced0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c49f1_row4_col0 {\n",
       "  background-color: #78abd0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c49f1_row5_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c49f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c49f1_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_c49f1_row0_col0\" class=\"data row0 col0\" >0.006003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_c49f1_row1_col0\" class=\"data row1 col0\" >0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_c49f1_row2_col0\" class=\"data row2 col0\" >0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_c49f1_row3_col0\" class=\"data row3 col0\" >0.044432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_c49f1_row4_col0\" class=\"data row4 col0\" >0.079355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c49f1_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_c49f1_row5_col0\" class=\"data row5 col0\" >0.156089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x174b480a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_partitions_to_cifar_iid_partitions = {}\n",
    "num_partitions_to_cifar_iid_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "for num_partitions in num_partitions_list:\n",
    "    iid_partitioner = IidPartitioner(num_partitions=num_partitions)\n",
    "    cifar_iid = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : iid_partitioner})\n",
    "    num_partitions_to_cifar_iid_fds[num_partitions] = cifar_iid\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_iid_hellinger_distance = {}\n",
    "num_partitions_to_cifar_iid_hellinger_distance_list = {}\n",
    "for num_partitions, cifar_iid_fds in num_partitions_to_cifar_iid_fds.items():\n",
    "    hellinger_distance_list, avg_hellinger_distance = compute_hellinger_distance(cifar_iid_fds.partitioners[\"train\"])\n",
    "    num_partitions_to_cifar_iid_hellinger_distance_list[num_partitions] = hellinger_distance_list\n",
    "    num_partitions_to_cifar_iid_hellinger_distance[num_partitions] = avg_hellinger_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f0ba04b-19a7-4cba-8d28-a89161f89770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ec5f3_row0_col0 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row1_col0 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row2_col0 {\n",
       "  background-color: #f0eaf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row3_col0 {\n",
       "  background-color: #ced0e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ec5f3_row4_col0 {\n",
       "  background-color: #78abd0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ec5f3_row5_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ec5f3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ec5f3_level0_col0\" class=\"col_heading level0 col0\" >iid_helinger</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_ec5f3_row0_col0\" class=\"data row0 col0\" >0.006003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_ec5f3_row1_col0\" class=\"data row1 col0\" >0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_ec5f3_row2_col0\" class=\"data row2 col0\" >0.021757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_ec5f3_row3_col0\" class=\"data row3 col0\" >0.044432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_ec5f3_row4_col0\" class=\"data row4 col0\" >0.079355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ec5f3_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_ec5f3_row5_col0\" class=\"data row5 col0\" >0.156089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x374c53a60>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iid_helinger_results = pd.Series(num_partitions_to_cifar_iid_hellinger_distance, name=\"iid_helinger\").to_frame().style.background_gradient()\n",
    "iid_helinger_results.index.name = \"num_partitions\"\n",
    "iid_helinger_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17cac8-2f3a-43e7-9811-734a954bd739",
   "metadata": {},
   "source": [
    "Is it desired to that degree? When the num_partitions is 1000, then each partition is of size 5. That can make it indeed heterogeneus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9a284c484fbf8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "60176581-022a-4a0c-8b62-4944436fe33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_partitions = 10\n",
    "alpha = [0.1] * 10\n",
    "dirichlet_partitioner = DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\")\n",
    "cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dirichlet_partitioner})\n",
    "cifar_dir_partitions = [cifar_dir.load_partition(i) for i in range(num_partitions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b38b1b41-2fca-42b7-a3de-5f31bed37fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.1)\n",
      "(3, 0.3)\n",
      "(3, 1.0)\n",
      "(3, 3.0)\n",
      "(3, 10.0)\n",
      "(3, 100.0)\n",
      "(10, 0.1)\n",
      "(10, 0.3)\n",
      "(10, 1.0)\n",
      "(10, 3.0)\n",
      "(10, 10.0)\n",
      "(10, 100.0)\n",
      "(30, 0.1)\n",
      "(30, 0.3)\n",
      "(30, 1.0)\n",
      "(30, 3.0)\n",
      "(30, 10.0)\n",
      "(30, 100.0)\n",
      "(100, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0.3)\n",
      "(100, 1.0)\n",
      "(100, 3.0)\n",
      "(100, 10.0)\n",
      "(100, 100.0)\n",
      "(300, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (300, 0.1)\n",
      "(300, 0.3)\n",
      "(300, 1.0)\n",
      "(300, 3.0)\n",
      "(300, 10.0)\n",
      "(300, 100.0)\n",
      "(1000, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.1)\n",
      "(1000, 0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3, 0.3]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.3)\n",
      "(1000, 1.0)\n",
      "(1000, 3.0)\n",
      "(1000, 10.0)\n",
      "(1000, 100.0)\n"
     ]
    }
   ],
   "source": [
    "num_partitions_to_cifar_dir_partitions = {}\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "for num_partitions, alpha in itertools.product(num_partitions_list, alpha_list):\n",
    "    dir_partitioner =  DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\", self_balancing=False)\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha)] = cifar_dir\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_hellinger_distance_list = {}\n",
    "num_partitions_to_cifar_dir_hellinger_distance = {}\n",
    "for (num_partitions, alpha), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha))\n",
    "    try:\n",
    "        hellinger_distance_list, avg_hellinger_distance = compute_hellinger_distance(cifar_dir_fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha)}\")\n",
    "        hellinger_distance_list, avg_hellinger_distance = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_hellinger_distance_list[(num_partitions, alpha)] = hellinger_distance_list\n",
    "    num_partitions_to_cifar_dir_hellinger_distance[(num_partitions, alpha)] = avg_hellinger_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4535e38e-99c1-4c89-8efe-e09eac516a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2a01_row0_col0 {\n",
       "  background-color: #1e80b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row0_col1 {\n",
       "  background-color: #60a1ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row0_col2 {\n",
       "  background-color: #b9c6e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row0_col3 {\n",
       "  background-color: #eae6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row0_col4 {\n",
       "  background-color: #f4edf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row0_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col0 {\n",
       "  background-color: #034e7b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row1_col1 {\n",
       "  background-color: #167bb6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row1_col2 {\n",
       "  background-color: #96b6d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col3 {\n",
       "  background-color: #dad9ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col4 {\n",
       "  background-color: #efe9f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row1_col5 {\n",
       "  background-color: #fef6fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col0 {\n",
       "  background-color: #023e62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row2_col1 {\n",
       "  background-color: #197db7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row2_col2 {\n",
       "  background-color: #91b5d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col3 {\n",
       "  background-color: #d3d4e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col4 {\n",
       "  background-color: #eee8f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row2_col5, #T_a2a01_row3_col5, #T_a2a01_row4_col5 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row3_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row3_col1 {\n",
       "  background-color: #0771b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row3_col2 {\n",
       "  background-color: #81aed2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row3_col3 {\n",
       "  background-color: #d0d1e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row3_col4 {\n",
       "  background-color: #ece7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row4_col0, #T_a2a01_row5_col0, #T_a2a01_row5_col1 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row4_col1 {\n",
       "  background-color: #056ead;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row4_col2 {\n",
       "  background-color: #86b0d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row4_col3 {\n",
       "  background-color: #d1d2e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row4_col4 {\n",
       "  background-color: #ede7f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row5_col2 {\n",
       "  background-color: #7bacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a2a01_row5_col3 {\n",
       "  background-color: #cccfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row5_col4 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a2a01_row5_col5 {\n",
       "  background-color: #fbf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2a01\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >alpha</th>\n",
       "      <th id=\"T_a2a01_level0_col0\" class=\"col_heading level0 col0\" >0.100000</th>\n",
       "      <th id=\"T_a2a01_level0_col1\" class=\"col_heading level0 col1\" >0.300000</th>\n",
       "      <th id=\"T_a2a01_level0_col2\" class=\"col_heading level0 col2\" >1.000000</th>\n",
       "      <th id=\"T_a2a01_level0_col3\" class=\"col_heading level0 col3\" >3.000000</th>\n",
       "      <th id=\"T_a2a01_level0_col4\" class=\"col_heading level0 col4\" >10.000000</th>\n",
       "      <th id=\"T_a2a01_level0_col5\" class=\"col_heading level0 col5\" >100.000000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_a2a01_row0_col0\" class=\"data row0 col0\" >0.465201</td>\n",
       "      <td id=\"T_a2a01_row0_col1\" class=\"data row0 col1\" >0.370950</td>\n",
       "      <td id=\"T_a2a01_row0_col2\" class=\"data row0 col2\" >0.227716</td>\n",
       "      <td id=\"T_a2a01_row0_col3\" class=\"data row0 col3\" >0.109010</td>\n",
       "      <td id=\"T_a2a01_row0_col4\" class=\"data row0 col4\" >0.071695</td>\n",
       "      <td id=\"T_a2a01_row0_col5\" class=\"data row0 col5\" >0.022788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_a2a01_row1_col0\" class=\"data row1 col0\" >0.613713</td>\n",
       "      <td id=\"T_a2a01_row1_col1\" class=\"data row1 col1\" >0.476372</td>\n",
       "      <td id=\"T_a2a01_row1_col2\" class=\"data row1 col2\" >0.290158</td>\n",
       "      <td id=\"T_a2a01_row1_col3\" class=\"data row1 col3\" >0.155027</td>\n",
       "      <td id=\"T_a2a01_row1_col4\" class=\"data row1 col4\" >0.091440</td>\n",
       "      <td id=\"T_a2a01_row1_col5\" class=\"data row1 col5\" >0.028729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_a2a01_row2_col0\" class=\"data row2 col0\" >0.651914</td>\n",
       "      <td id=\"T_a2a01_row2_col1\" class=\"data row2 col1\" >0.471448</td>\n",
       "      <td id=\"T_a2a01_row2_col2\" class=\"data row2 col2\" >0.297516</td>\n",
       "      <td id=\"T_a2a01_row2_col3\" class=\"data row2 col3\" >0.174453</td>\n",
       "      <td id=\"T_a2a01_row2_col4\" class=\"data row2 col4\" >0.097322</td>\n",
       "      <td id=\"T_a2a01_row2_col5\" class=\"data row2 col5\" >0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_a2a01_row3_col0\" class=\"data row3 col0\" >0.667463</td>\n",
       "      <td id=\"T_a2a01_row3_col1\" class=\"data row3 col1\" >0.503658</td>\n",
       "      <td id=\"T_a2a01_row3_col2\" class=\"data row3 col2\" >0.324196</td>\n",
       "      <td id=\"T_a2a01_row3_col3\" class=\"data row3 col3\" >0.186368</td>\n",
       "      <td id=\"T_a2a01_row3_col4\" class=\"data row3 col4\" >0.103555</td>\n",
       "      <td id=\"T_a2a01_row3_col5\" class=\"data row3 col5\" >0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_a2a01_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_a2a01_row4_col1\" class=\"data row4 col1\" >0.511364</td>\n",
       "      <td id=\"T_a2a01_row4_col2\" class=\"data row4 col2\" >0.315759</td>\n",
       "      <td id=\"T_a2a01_row4_col3\" class=\"data row4 col3\" >0.182981</td>\n",
       "      <td id=\"T_a2a01_row4_col4\" class=\"data row4 col4\" >0.101346</td>\n",
       "      <td id=\"T_a2a01_row4_col5\" class=\"data row4 col5\" >0.032604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2a01_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_a2a01_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_a2a01_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_a2a01_row5_col2\" class=\"data row5 col2\" >0.334892</td>\n",
       "      <td id=\"T_a2a01_row5_col3\" class=\"data row5 col3\" >0.191701</td>\n",
       "      <td id=\"T_a2a01_row5_col4\" class=\"data row5 col4\" >0.106884</td>\n",
       "      <td id=\"T_a2a01_row5_col5\" class=\"data row5 col5\" >0.042349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3752ac6a0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hel_dir = pd.Series(num_partitions_to_cifar_dir_hellinger_distance).unstack(level=1)#.style.background_gradient(axis=None)\n",
    "hel_dir.index.name = \"num_partitions\"\n",
    "hel_dir.columns.name = \"alpha\"\n",
    "hel_dir.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63b4df5d-9535-40dc-9a35-65ed944489bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.1)\n",
      "(3, 0.3)\n",
      "(3, 1.0)\n",
      "(3, 3.0)\n",
      "(3, 10.0)\n",
      "(3, 100.0)\n",
      "(10, 0.1)\n",
      "(10, 0.3)\n",
      "(10, 1.0)\n",
      "(10, 3.0)\n",
      "(10, 10.0)\n",
      "(10, 100.0)\n",
      "(30, 0.1)\n",
      "(30, 0.3)\n",
      "(30, 1.0)\n",
      "(30, 3.0)\n",
      "(30, 10.0)\n",
      "(30, 100.0)\n",
      "(100, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0.3)\n",
      "(100, 1.0)\n",
      "(100, 3.0)\n",
      "(100, 10.0)\n",
      "(100, 100.0)\n",
      "(300, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (300, 0.1)\n",
      "(300, 0.3)\n",
      "(300, 1.0)\n",
      "(300, 3.0)\n",
      "(300, 10.0)\n",
      "(300, 100.0)\n",
      "(1000, 0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.1) and minimum alpha (0.1) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.1)\n",
      "(1000, 0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3, 0.3, 0.3]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 7 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 8 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 9 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/Users/adam/.pyenv/versions/fl-heterogeneity/lib/python3.10/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:285: UserWarning: The specified min_partition_size (10) was not satisfied for alpha ([0.3]) after 10 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.3) and minimum alpha (0.3) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling failed for (1000, 0.3)\n",
      "(1000, 1.0)\n",
      "(1000, 3.0)\n",
      "(1000, 10.0)\n",
      "(1000, 100.0)\n"
     ]
    }
   ],
   "source": [
    "num_partitions_to_cifar_dir_partitions = {}\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "for num_partitions, alpha in itertools.product(num_partitions_list, alpha_list):\n",
    "    dir_partitioner =  DirichletPartitioner(num_partitions=num_partitions, alpha=alpha, partition_by=\"label\", self_balancing=True)\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha)] = cifar_dir\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_hellinger_distance_list = {}\n",
    "num_partitions_to_cifar_dir_hellinger_distance = {}\n",
    "for (num_partitions, alpha), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha))\n",
    "    try:\n",
    "        hellinger_distance_list, avg_hellinger_distance = hellinger_distance(cifar_dir_fds, \"train\")\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha)}\")\n",
    "        hellinger_distance_list, avg_hellinger_distance = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_hellinger_distance_list[(num_partitions, alpha)] = hellinger_distance_list\n",
    "    num_partitions_to_cifar_dir_hellinger_distance[(num_partitions, alpha)] = avg_hellinger_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4e3afe2-e52b-4983-bd76-be6dea58f9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_af86b_row0_col0 {\n",
       "  background-color: #056ba7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row0_col1 {\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row0_col2 {\n",
       "  background-color: #a5bddb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row0_col3 {\n",
       "  background-color: #dcdaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row0_col4 {\n",
       "  background-color: #f5eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row0_col5 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row1_col0 {\n",
       "  background-color: #034369;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row1_col1 {\n",
       "  background-color: #0d75b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row1_col2 {\n",
       "  background-color: #75a9cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row1_col3 {\n",
       "  background-color: #c4cbe3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row1_col4 {\n",
       "  background-color: #e4e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row1_col5, #T_af86b_row2_col5 {\n",
       "  background-color: #fef6fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row2_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row2_col1 {\n",
       "  background-color: #056dab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row2_col2 {\n",
       "  background-color: #69a5cc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row2_col3, #T_af86b_row5_col3 {\n",
       "  background-color: #bdc8e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row2_col4 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row3_col0 {\n",
       "  background-color: #023a5b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row3_col1 {\n",
       "  background-color: #056aa6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row3_col2 {\n",
       "  background-color: #6ba5cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row3_col3, #T_af86b_row4_col3 {\n",
       "  background-color: #bcc7e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row3_col4 {\n",
       "  background-color: #e7e3f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row3_col5, #T_af86b_row4_col5 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row4_col0, #T_af86b_row5_col0, #T_af86b_row5_col1 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row4_col1 {\n",
       "  background-color: #0567a1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row4_col2 {\n",
       "  background-color: #6da6cd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row4_col4 {\n",
       "  background-color: #e5e1ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row5_col2 {\n",
       "  background-color: #63a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_af86b_row5_col4 {\n",
       "  background-color: #e6e2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_af86b_row5_col5 {\n",
       "  background-color: #fbf3f9;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_af86b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_af86b_level0_col0\" class=\"col_heading level0 col0\" colspan=\"6\">0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_af86b_level1_col0\" class=\"col_heading level1 col0\" >0.100000</th>\n",
       "      <th id=\"T_af86b_level1_col1\" class=\"col_heading level1 col1\" >0.300000</th>\n",
       "      <th id=\"T_af86b_level1_col2\" class=\"col_heading level1 col2\" >1.000000</th>\n",
       "      <th id=\"T_af86b_level1_col3\" class=\"col_heading level1 col3\" >3.000000</th>\n",
       "      <th id=\"T_af86b_level1_col4\" class=\"col_heading level1 col4\" >10.000000</th>\n",
       "      <th id=\"T_af86b_level1_col5\" class=\"col_heading level1 col5\" >100.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_af86b_row0_col0\" class=\"data row0 col0\" >0.567639</td>\n",
       "      <td id=\"T_af86b_row0_col1\" class=\"data row0 col1\" >0.440146</td>\n",
       "      <td id=\"T_af86b_row0_col2\" class=\"data row0 col2\" >0.287541</td>\n",
       "      <td id=\"T_af86b_row0_col3\" class=\"data row0 col3\" >0.161999</td>\n",
       "      <td id=\"T_af86b_row0_col4\" class=\"data row0 col4\" >0.071695</td>\n",
       "      <td id=\"T_af86b_row0_col5\" class=\"data row0 col5\" >0.022788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_af86b_row1_col0\" class=\"data row1 col0\" >0.691987</td>\n",
       "      <td id=\"T_af86b_row1_col1\" class=\"data row1 col1\" >0.530651</td>\n",
       "      <td id=\"T_af86b_row1_col2\" class=\"data row1 col2\" >0.371551</td>\n",
       "      <td id=\"T_af86b_row1_col3\" class=\"data row1 col3\" >0.223615</td>\n",
       "      <td id=\"T_af86b_row1_col4\" class=\"data row1 col4\" >0.134834</td>\n",
       "      <td id=\"T_af86b_row1_col5\" class=\"data row1 col5\" >0.028729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_af86b_row2_col0\" class=\"data row2 col0\" >0.721607</td>\n",
       "      <td id=\"T_af86b_row2_col1\" class=\"data row2 col1\" >0.558678</td>\n",
       "      <td id=\"T_af86b_row2_col2\" class=\"data row2 col2\" >0.387039</td>\n",
       "      <td id=\"T_af86b_row2_col3\" class=\"data row2 col3\" >0.238245</td>\n",
       "      <td id=\"T_af86b_row2_col4\" class=\"data row2 col4\" >0.115445</td>\n",
       "      <td id=\"T_af86b_row2_col5\" class=\"data row2 col5\" >0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_af86b_row3_col0\" class=\"data row3 col0\" >0.715659</td>\n",
       "      <td id=\"T_af86b_row3_col1\" class=\"data row3 col1\" >0.569919</td>\n",
       "      <td id=\"T_af86b_row3_col2\" class=\"data row3 col2\" >0.384234</td>\n",
       "      <td id=\"T_af86b_row3_col3\" class=\"data row3 col3\" >0.240813</td>\n",
       "      <td id=\"T_af86b_row3_col4\" class=\"data row3 col4\" >0.125372</td>\n",
       "      <td id=\"T_af86b_row3_col5\" class=\"data row3 col5\" >0.032853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_af86b_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_af86b_row4_col1\" class=\"data row4 col1\" >0.583560</td>\n",
       "      <td id=\"T_af86b_row4_col2\" class=\"data row4 col2\" >0.381126</td>\n",
       "      <td id=\"T_af86b_row4_col3\" class=\"data row4 col3\" >0.238532</td>\n",
       "      <td id=\"T_af86b_row4_col4\" class=\"data row4 col4\" >0.132240</td>\n",
       "      <td id=\"T_af86b_row4_col5\" class=\"data row4 col5\" >0.032604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af86b_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_af86b_row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "      <td id=\"T_af86b_row5_col1\" class=\"data row5 col1\" >nan</td>\n",
       "      <td id=\"T_af86b_row5_col2\" class=\"data row5 col2\" >0.396759</td>\n",
       "      <td id=\"T_af86b_row5_col3\" class=\"data row5 col3\" >0.236577</td>\n",
       "      <td id=\"T_af86b_row5_col4\" class=\"data row5 col4\" >0.129837</td>\n",
       "      <td id=\"T_af86b_row5_col5\" class=\"data row5 col5\" >0.042934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11ad6c130>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(num_partitions_to_cifar_dir_hellinger_distance).to_frame().unstack(level=1).style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e0e67-2aaa-4d03-9f9b-3c158fd1283f",
   "metadata": {},
   "source": [
    "The self_balancing (size balancing) creates more heterogenous dataset division."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a7086-602f-4606-9675-660a9e64cfe9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3428971c-5551-4539-a363-25827a182dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 3)\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "(10, 2)\n",
      "(10, 3)\n",
      "(10, 4)\n",
      "(10, 5)\n",
      "(30, 2)\n",
      "(30, 3)\n",
      "(30, 4)\n",
      "(30, 5)\n",
      "(100, 2)\n",
      "(100, 3)\n",
      "(100, 4)\n",
      "(100, 5)\n",
      "(300, 2)\n",
      "(300, 3)\n",
      "(300, 4)\n",
      "(300, 5)\n",
      "(1000, 2)\n",
      "(1000, 3)\n",
      "(1000, 4)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "params_to_partitioner = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "num_shards_per_partition_list = [2, 3, 4, 5]\n",
    "for num_partitions, num_shards_per_partition in itertools.product(num_partitions_list, num_shards_per_partition_list):\n",
    "    partitioner = ShardPartitioner(num_partitions=num_partitions, partition_by=\"label\", num_shards_per_partition=num_shards_per_partition)\n",
    "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : partitioner})\n",
    "    params_to_partitioner[(num_partitions, num_shards_per_partition)] = fds\n",
    "\n",
    "parameters_to_shard_cifar_fds_metric_list = {}\n",
    "parameters_to_shard_cifar_fds_metric = {}\n",
    "for (num_partitions, num_shards_per_partition), fds in params_to_partitioner.items():\n",
    "    print((num_partitions, num_shards_per_partition))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_hellinger_distance(fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, num_shards_per_partition)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    parameters_to_shard_cifar_fds_metric_list[(num_partitions, num_shards_per_partition)] = metric_list\n",
    "    parameters_to_shard_cifar_fds_metric[(num_partitions, num_shards_per_partition)] = avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e698d33c-0b02-4db5-9597-de6b616fef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4443_row0_col0 {\n",
       "  background-color: #81aed2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row0_col1, #T_e4443_row0_col3 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row0_col2 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row1_col0 {\n",
       "  background-color: #034165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row1_col1 {\n",
       "  background-color: #0d75b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row1_col2 {\n",
       "  background-color: #4094c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row1_col3 {\n",
       "  background-color: #9cb9d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row2_col0, #T_e4443_row4_col0, #T_e4443_row5_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row2_col1 {\n",
       "  background-color: #056dab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row2_col2 {\n",
       "  background-color: #63a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row2_col3 {\n",
       "  background-color: #a9bfdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row3_col0 {\n",
       "  background-color: #023b5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row3_col1 {\n",
       "  background-color: #0771b1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row3_col2 {\n",
       "  background-color: #4697c4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row3_col3 {\n",
       "  background-color: #8eb3d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row4_col1 {\n",
       "  background-color: #056fae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row4_col2 {\n",
       "  background-color: #4c99c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row4_col3 {\n",
       "  background-color: #8fb4d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_e4443_row5_col1 {\n",
       "  background-color: #056caa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row5_col2 {\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_e4443_row5_col3 {\n",
       "  background-color: #96b6d7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4443\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_shards</th>\n",
       "      <th id=\"T_e4443_level0_col0\" class=\"col_heading level0 col0\" >2</th>\n",
       "      <th id=\"T_e4443_level0_col1\" class=\"col_heading level0 col1\" >3</th>\n",
       "      <th id=\"T_e4443_level0_col2\" class=\"col_heading level0 col2\" >4</th>\n",
       "      <th id=\"T_e4443_level0_col3\" class=\"col_heading level0 col3\" >5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >num_partitions</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_e4443_row0_col0\" class=\"data row0 col0\" >0.614130</td>\n",
       "      <td id=\"T_e4443_row0_col1\" class=\"data row0 col1\" >0.506585</td>\n",
       "      <td id=\"T_e4443_row0_col2\" class=\"data row0 col2\" >0.493643</td>\n",
       "      <td id=\"T_e4443_row0_col3\" class=\"data row0 col3\" >0.506547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row1\" class=\"row_heading level0 row1\" >10</th>\n",
       "      <td id=\"T_e4443_row1_col0\" class=\"data row1 col0\" >0.743496</td>\n",
       "      <td id=\"T_e4443_row1_col1\" class=\"data row1 col1\" >0.681302</td>\n",
       "      <td id=\"T_e4443_row1_col2\" class=\"data row1 col2\" >0.649515</td>\n",
       "      <td id=\"T_e4443_row1_col3\" class=\"data row1 col3\" >0.597347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row2\" class=\"row_heading level0 row2\" >30</th>\n",
       "      <td id=\"T_e4443_row2_col0\" class=\"data row2 col0\" >0.750597</td>\n",
       "      <td id=\"T_e4443_row2_col1\" class=\"data row2 col1\" >0.692119</td>\n",
       "      <td id=\"T_e4443_row2_col2\" class=\"data row2 col2\" >0.630778</td>\n",
       "      <td id=\"T_e4443_row2_col3\" class=\"data row2 col3\" >0.588314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row3\" class=\"row_heading level0 row3\" >100</th>\n",
       "      <td id=\"T_e4443_row3_col0\" class=\"data row3 col0\" >0.748501</td>\n",
       "      <td id=\"T_e4443_row3_col1\" class=\"data row3 col1\" >0.685527</td>\n",
       "      <td id=\"T_e4443_row3_col2\" class=\"data row3 col2\" >0.645899</td>\n",
       "      <td id=\"T_e4443_row3_col3\" class=\"data row3 col3\" >0.605997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row4\" class=\"row_heading level0 row4\" >300</th>\n",
       "      <td id=\"T_e4443_row4_col0\" class=\"data row4 col0\" >0.751315</td>\n",
       "      <td id=\"T_e4443_row4_col1\" class=\"data row4 col1\" >0.689076</td>\n",
       "      <td id=\"T_e4443_row4_col2\" class=\"data row4 col2\" >0.643505</td>\n",
       "      <td id=\"T_e4443_row4_col3\" class=\"data row4 col3\" >0.605235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4443_level0_row5\" class=\"row_heading level0 row5\" >1000</th>\n",
       "      <td id=\"T_e4443_row5_col0\" class=\"data row5 col0\" >0.751587</td>\n",
       "      <td id=\"T_e4443_row5_col1\" class=\"data row5 col1\" >0.692730</td>\n",
       "      <td id=\"T_e4443_row5_col2\" class=\"data row5 col2\" >0.647640</td>\n",
       "      <td id=\"T_e4443_row5_col3\" class=\"data row5 col3\" >0.600940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x36415bf70>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_emd_results = pd.Series(parameters_to_shard_cifar_fds_metric).unstack(level=1)\n",
    "shard_emd_results.index.name = \"num_partitions\"\n",
    "shard_emd_results.columns.name = \"num_shards\"\n",
    "shard_emd_results.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "476d1793-1474-401a-aeff-f07e3240b618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>2</th>\n",
       "      <td>0.614130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.506547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th>2</th>\n",
       "      <td>0.743496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.681302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.597347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">30</th>\n",
       "      <th>2</th>\n",
       "      <td>0.750597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.692119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.630778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.588314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>2</th>\n",
       "      <td>0.748501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.685527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.605997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">300</th>\n",
       "      <th>2</th>\n",
       "      <td>0.751315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.643505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.605235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1000</th>\n",
       "      <th>2</th>\n",
       "      <td>0.751587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.692730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                \n",
       "3    2  0.614130\n",
       "     3  0.506585\n",
       "     4  0.493643\n",
       "     5  0.506547\n",
       "10   2  0.743496\n",
       "     3  0.681302\n",
       "     4  0.649515\n",
       "     5  0.597347\n",
       "30   2  0.750597\n",
       "     3  0.692119\n",
       "     4  0.630778\n",
       "     5  0.588314\n",
       "100  2  0.748501\n",
       "     3  0.685527\n",
       "     4  0.645899\n",
       "     5  0.605997\n",
       "300  2  0.751315\n",
       "     3  0.689076\n",
       "     4  0.643505\n",
       "     5  0.605235\n",
       "1000 2  0.751587\n",
       "     3  0.692730\n",
       "     4  0.647640\n",
       "     5  0.600940"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_emd_results"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inner Dirichlet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5094db914cee065b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0.1, 0.1)\n",
      "(3, 0.1, 0.3)\n",
      "(3, 0.1, 1.0)\n",
      "(3, 0.1, 3.0)\n",
      "(3, 0.3, 0.1)\n",
      "(3, 0.3, 0.3)\n",
      "(3, 0.3, 1.0)\n",
      "(3, 0.3, 3.0)\n",
      "(3, 1.0, 0.1)\n",
      "(3, 1.0, 0.3)\n",
      "(3, 1.0, 1.0)\n",
      "(3, 1.0, 3.0)\n",
      "(3, 3.0, 0.1)\n",
      "(3, 3.0, 0.3)\n",
      "(3, 3.0, 1.0)\n",
      "(3, 3.0, 3.0)\n",
      "(3, 10.0, 0.1)\n",
      "(3, 10.0, 0.3)\n",
      "(3, 10.0, 1.0)\n",
      "(3, 10.0, 3.0)\n",
      "(3, 100.0, 0.1)\n",
      "(3, 100.0, 0.3)\n",
      "(3, 100.0, 1.0)\n",
      "(3, 100.0, 3.0)\n",
      "(10, 0.1, 0.1)\n",
      "(10, 0.1, 0.3)\n",
      "(10, 0.1, 1.0)\n",
      "(10, 0.1, 3.0)\n",
      "(10, 0.3, 0.1)\n",
      "(10, 0.3, 0.3)\n",
      "(10, 0.3, 1.0)\n",
      "(10, 0.3, 3.0)\n",
      "(10, 1.0, 0.1)\n",
      "(10, 1.0, 0.3)\n",
      "(10, 1.0, 1.0)\n",
      "(10, 1.0, 3.0)\n",
      "(10, 3.0, 0.1)\n",
      "(10, 3.0, 0.3)\n",
      "(10, 3.0, 1.0)\n",
      "(10, 3.0, 3.0)\n",
      "(10, 10.0, 0.1)\n",
      "(10, 10.0, 0.3)\n",
      "(10, 10.0, 1.0)\n",
      "(10, 10.0, 3.0)\n",
      "(10, 100.0, 0.1)\n",
      "(10, 100.0, 0.3)\n",
      "(10, 100.0, 1.0)\n",
      "(10, 100.0, 3.0)\n",
      "(30, 0.1, 0.1)\n",
      "(30, 0.1, 0.3)\n",
      "(30, 0.1, 1.0)\n",
      "(30, 0.1, 3.0)\n",
      "(30, 0.3, 0.1)\n",
      "(30, 0.3, 0.3)\n",
      "(30, 0.3, 1.0)\n",
      "(30, 0.3, 3.0)\n",
      "(30, 1.0, 0.1)\n",
      "(30, 1.0, 0.3)\n",
      "(30, 1.0, 1.0)\n",
      "(30, 1.0, 3.0)\n",
      "(30, 3.0, 0.1)\n",
      "(30, 3.0, 0.3)\n",
      "(30, 3.0, 1.0)\n",
      "(30, 3.0, 3.0)\n",
      "(30, 10.0, 0.1)\n",
      "(30, 10.0, 0.3)\n",
      "(30, 10.0, 1.0)\n",
      "(30, 10.0, 3.0)\n",
      "(30, 100.0, 0.1)\n",
      "(30, 100.0, 0.3)\n",
      "(30, 100.0, 1.0)\n",
      "(30, 100.0, 3.0)\n",
      "(100, 0.1, 0.1)\n",
      "(100, 0.1, 0.3)\n",
      "(100, 0.1, 1.0)\n",
      "(100, 0.1, 3.0)\n",
      "(100, 0.3, 0.1)\n",
      "(100, 0.3, 0.3)\n",
      "(100, 0.3, 1.0)\n",
      "(100, 0.3, 3.0)\n",
      "(100, 1.0, 0.1)\n",
      "(100, 1.0, 0.3)\n",
      "(100, 1.0, 1.0)\n",
      "(100, 1.0, 3.0)\n",
      "(100, 3.0, 0.1)\n",
      "(100, 3.0, 0.3)\n",
      "(100, 3.0, 1.0)\n",
      "(100, 3.0, 3.0)\n",
      "(100, 10.0, 0.1)\n",
      "(100, 10.0, 0.3)\n",
      "(100, 10.0, 1.0)\n",
      "(100, 10.0, 3.0)\n",
      "(100, 100.0, 0.1)\n",
      "(100, 100.0, 0.3)\n",
      "(100, 100.0, 1.0)\n",
      "(100, 100.0, 3.0)\n",
      "(300, 0.1, 0.1)\n",
      "(300, 0.1, 0.3)\n",
      "(300, 0.1, 1.0)\n",
      "(300, 0.1, 3.0)\n",
      "(300, 0.3, 0.1)\n",
      "(300, 0.3, 0.3)\n",
      "(300, 0.3, 1.0)\n",
      "(300, 0.3, 3.0)\n",
      "(300, 1.0, 0.1)\n",
      "(300, 1.0, 0.3)\n",
      "(300, 1.0, 1.0)\n",
      "(300, 1.0, 3.0)\n",
      "(300, 3.0, 0.1)\n",
      "(300, 3.0, 0.3)\n",
      "(300, 3.0, 1.0)\n",
      "(300, 3.0, 3.0)\n",
      "(300, 10.0, 0.1)\n",
      "(300, 10.0, 0.3)\n",
      "(300, 10.0, 1.0)\n",
      "(300, 10.0, 3.0)\n",
      "(300, 100.0, 0.1)\n",
      "(300, 100.0, 0.3)\n",
      "(300, 100.0, 1.0)\n",
      "(300, 100.0, 3.0)\n",
      "(1000, 0.1, 0.1)\n",
      "(1000, 0.1, 0.3)\n",
      "(1000, 0.1, 1.0)\n",
      "(1000, 0.1, 3.0)\n",
      "(1000, 0.3, 0.1)\n",
      "(1000, 0.3, 0.3)\n",
      "(1000, 0.3, 1.0)\n",
      "(1000, 0.3, 3.0)\n",
      "(1000, 1.0, 0.1)\n",
      "(1000, 1.0, 0.3)\n",
      "(1000, 1.0, 1.0)\n",
      "(1000, 1.0, 3.0)\n",
      "(1000, 3.0, 0.1)\n",
      "(1000, 3.0, 0.3)\n",
      "(1000, 3.0, 1.0)\n",
      "(1000, 3.0, 3.0)\n",
      "(1000, 10.0, 0.1)\n",
      "(1000, 10.0, 0.3)\n",
      "(1000, 10.0, 1.0)\n",
      "(1000, 10.0, 3.0)\n",
      "(1000, 100.0, 0.1)\n",
      "(1000, 100.0, 0.3)\n",
      "(1000, 100.0, 1.0)\n",
      "(1000, 100.0, 3.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_name = \"cifar10\"\n",
    "# num_partitions = 10\n",
    "# sigma = 0.3\n",
    "# partition_sizes = create_lognormal_partition_sizes(dataset_name, num_partitions, sigma)\n",
    "# \n",
    "# alpha = 0.1\n",
    "# dirichlet_partitioner = InnerDirichletPartitioner(partition_sizes=partition_sizes, partition_by=\"label\", alpha=0.1)\n",
    "# cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dirichlet_partitioner})\n",
    "# cifar_dir_partitions = [cifar_dir.load_partition(i) for i in range(num_partitions)]\n",
    "\n",
    "num_partitions_to_cifar_dir_fds = {}\n",
    "num_partitions_list = [3, 10, 30, 100, 300, 1000]\n",
    "alpha_list = [0.1, 0.3, 1., 3., 10., 100., 100.]\n",
    "sigma_list = [0.1, 0.3, 1., 3.]\n",
    "partition_sizes_dict = {}\n",
    "for num_partitions, alpha, sigma in itertools.product(num_partitions_list, alpha_list, sigma_list):\n",
    "    partition_sizes = create_lognormal_partition_sizes(dataset_name, num_partitions, sigma)\n",
    "    dir_partitioner =  InnerDirichletPartitioner(partition_sizes=partition_sizes, partition_by=\"label\", alpha=alpha)\n",
    "    cifar_dir = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\" : dir_partitioner})\n",
    "    num_partitions_to_cifar_dir_fds[(num_partitions, alpha, sigma)] = cifar_dir\n",
    "    partition_sizes_dict[(num_partitions, alpha, sigma)] = partition_sizes\n",
    "    # cifar_iid_partitions = [cifar_iid.load_partition(i) for i in range(num_partitions)]\n",
    "    # num_partitions_to_cifar_iid_partitions[num_partitions] = cifar_iid_partitions\n",
    "\n",
    "num_partitions_to_cifar_dir_metric_list = {}\n",
    "num_partitions_to_cifar_dir_metric = {}\n",
    "for (num_partitions, alpha, sigma), cifar_dir_fds in num_partitions_to_cifar_dir_fds.items():\n",
    "    print((num_partitions, alpha, sigma))\n",
    "    try:\n",
    "        metric_list, avg_metric = compute_hellinger_distance(cifar_dir_fds.partitioners[\"train\"])\n",
    "    except:\n",
    "        print(f\"Sampling failed for {(num_partitions, alpha, sigma)}\")\n",
    "        metric_list, avg_metric = np.nan, np.nan\n",
    "    num_partitions_to_cifar_dir_metric_list[(num_partitions, alpha, sigma)] = metric_list\n",
    "    num_partitions_to_cifar_dir_metric[(num_partitions, alpha, sigma)] = avg_metric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:39:20.209425Z",
     "start_time": "2024-03-26T10:11:09.631309Z"
    }
   },
   "id": "147f8f697538b893",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             0.1       0.3       1.0       3.0       10.0      100.0\n3    0.1  0.483508  0.364196  0.250555  0.108401  0.072891  0.030356\n     0.3  0.494047  0.343726  0.258034  0.102252  0.085942  0.028757\n     1.0  0.471969  0.307708  0.246051  0.070965  0.063238  0.022935\n     3.0  0.238923  0.165851  0.116684  0.029693  0.032669  0.012412\n10   0.1  0.584711  0.454895  0.285363  0.156336  0.095770  0.034429\n     0.3  0.587107  0.465040  0.287058  0.162426  0.100059  0.037311\n     1.0  0.570039  0.455282  0.269609  0.158307  0.092282  0.035062\n     3.0  0.384673  0.333791  0.214212  0.132107  0.072512  0.023159\n30   0.1  0.597490  0.473332  0.288085  0.176022  0.103820  0.042910\n     0.3  0.605434  0.475120  0.295075  0.176015  0.101295  0.040185\n     1.0  0.610153  0.469364  0.296169  0.166457  0.101360  0.043845\n     3.0  0.615326  0.447103  0.260554  0.146483  0.080724  0.032345\n100  0.1  0.640688  0.501183  0.319237  0.191886  0.115700  0.058543\n     0.3  0.646065  0.507550  0.319772  0.190689  0.116527  0.059742\n     1.0  0.648479  0.498424  0.319748  0.193316  0.113606  0.055124\n     3.0  0.371478  0.292248  0.195735  0.109174  0.061045  0.031813\n300  0.1  0.660396  0.510941  0.330515  0.203285  0.134432  0.088340\n     0.3  0.664574  0.517540  0.330868  0.202558  0.133288  0.086789\n     1.0  0.659944  0.512140  0.332754  0.201807  0.133779  0.081769\n     3.0  0.544277  0.407300  0.259562  0.155716  0.120061  0.050205\n1000 0.1  0.675733  0.547433  0.378343  0.259873  0.193808  0.161686\n     0.3  0.676098  0.549194  0.378806  0.259359  0.193626  0.160609\n     1.0  0.670515  0.544317  0.370504  0.254231  0.187761  0.151084\n     3.0  0.584844  0.477425  0.261066  0.186784  0.122393  0.069684",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0.1</th>\n      <th>0.3</th>\n      <th>1.0</th>\n      <th>3.0</th>\n      <th>10.0</th>\n      <th>100.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">3</th>\n      <th>0.1</th>\n      <td>0.483508</td>\n      <td>0.364196</td>\n      <td>0.250555</td>\n      <td>0.108401</td>\n      <td>0.072891</td>\n      <td>0.030356</td>\n    </tr>\n    <tr>\n      <th>0.3</th>\n      <td>0.494047</td>\n      <td>0.343726</td>\n      <td>0.258034</td>\n      <td>0.102252</td>\n      <td>0.085942</td>\n      <td>0.028757</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.471969</td>\n      <td>0.307708</td>\n      <td>0.246051</td>\n      <td>0.070965</td>\n      <td>0.063238</td>\n      <td>0.022935</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.238923</td>\n      <td>0.165851</td>\n      <td>0.116684</td>\n      <td>0.029693</td>\n      <td>0.032669</td>\n      <td>0.012412</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">10</th>\n      <th>0.1</th>\n      <td>0.584711</td>\n      <td>0.454895</td>\n      <td>0.285363</td>\n      <td>0.156336</td>\n      <td>0.095770</td>\n      <td>0.034429</td>\n    </tr>\n    <tr>\n      <th>0.3</th>\n      <td>0.587107</td>\n      <td>0.465040</td>\n      <td>0.287058</td>\n      <td>0.162426</td>\n      <td>0.100059</td>\n      <td>0.037311</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.570039</td>\n      <td>0.455282</td>\n      <td>0.269609</td>\n      <td>0.158307</td>\n      <td>0.092282</td>\n      <td>0.035062</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.384673</td>\n      <td>0.333791</td>\n      <td>0.214212</td>\n      <td>0.132107</td>\n      <td>0.072512</td>\n      <td>0.023159</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">30</th>\n      <th>0.1</th>\n      <td>0.597490</td>\n      <td>0.473332</td>\n      <td>0.288085</td>\n      <td>0.176022</td>\n      <td>0.103820</td>\n      <td>0.042910</td>\n    </tr>\n    <tr>\n      <th>0.3</th>\n      <td>0.605434</td>\n      <td>0.475120</td>\n      <td>0.295075</td>\n      <td>0.176015</td>\n      <td>0.101295</td>\n      <td>0.040185</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.610153</td>\n      <td>0.469364</td>\n      <td>0.296169</td>\n      <td>0.166457</td>\n      <td>0.101360</td>\n      <td>0.043845</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.615326</td>\n      <td>0.447103</td>\n      <td>0.260554</td>\n      <td>0.146483</td>\n      <td>0.080724</td>\n      <td>0.032345</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">100</th>\n      <th>0.1</th>\n      <td>0.640688</td>\n      <td>0.501183</td>\n      <td>0.319237</td>\n      <td>0.191886</td>\n      <td>0.115700</td>\n      <td>0.058543</td>\n    </tr>\n    <tr>\n      <th>0.3</th>\n      <td>0.646065</td>\n      <td>0.507550</td>\n      <td>0.319772</td>\n      <td>0.190689</td>\n      <td>0.116527</td>\n      <td>0.059742</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.648479</td>\n      <td>0.498424</td>\n      <td>0.319748</td>\n      <td>0.193316</td>\n      <td>0.113606</td>\n      <td>0.055124</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.371478</td>\n      <td>0.292248</td>\n      <td>0.195735</td>\n      <td>0.109174</td>\n      <td>0.061045</td>\n      <td>0.031813</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">300</th>\n      <th>0.1</th>\n      <td>0.660396</td>\n      <td>0.510941</td>\n      <td>0.330515</td>\n      <td>0.203285</td>\n      <td>0.134432</td>\n      <td>0.088340</td>\n    </tr>\n    <tr>\n      <th>0.3</th>\n      <td>0.664574</td>\n      <td>0.517540</td>\n      <td>0.330868</td>\n      <td>0.202558</td>\n      <td>0.133288</td>\n      <td>0.086789</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.659944</td>\n      <td>0.512140</td>\n      <td>0.332754</td>\n      <td>0.201807</td>\n      <td>0.133779</td>\n      <td>0.081769</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.544277</td>\n      <td>0.407300</td>\n      <td>0.259562</td>\n      <td>0.155716</td>\n      <td>0.120061</td>\n      <td>0.050205</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1000</th>\n      <th>0.1</th>\n      <td>0.675733</td>\n      <td>0.547433</td>\n      <td>0.378343</td>\n      <td>0.259873</td>\n      <td>0.193808</td>\n      <td>0.161686</td>\n    </tr>\n    <tr>\n      <th>0.3</th>\n      <td>0.676098</td>\n      <td>0.549194</td>\n      <td>0.378806</td>\n      <td>0.259359</td>\n      <td>0.193626</td>\n      <td>0.160609</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.670515</td>\n      <td>0.544317</td>\n      <td>0.370504</td>\n      <td>0.254231</td>\n      <td>0.187761</td>\n      <td>0.151084</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.584844</td>\n      <td>0.477425</td>\n      <td>0.261066</td>\n      <td>0.186784</td>\n      <td>0.122393</td>\n      <td>0.069684</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emd_dir = pd.Series(num_partitions_to_cifar_dir_metric, name=\"emd_inner_dir\").unstack(level=1)\n",
    "emd_dir"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:43:11.252765Z",
     "start_time": "2024-03-26T10:43:11.228532Z"
    }
   },
   "id": "960d47c955d33d62",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([5310, 4642, 5552, 5659, 4237, 4522, 5217, 4990, 5142, 4729])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_sizes_dict[(10, 0.3, 0.1)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:45:48.130784Z",
     "start_time": "2024-03-26T10:45:48.108916Z"
    }
   },
   "id": "df3ae8d8b725aadc",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3929,    70, 14961, 26465,     5,    32,  2311,   609,  1497,\n         121])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_sizes_dict[(10, 0.3, 3)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T10:45:54.873466Z",
     "start_time": "2024-03-26T10:45:54.856944Z"
    }
   },
   "id": "5fb8e611212c4bf0",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fcb0f1631cb404dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-heterogeneity",
   "language": "python",
   "name": "fl-heterogeneity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
